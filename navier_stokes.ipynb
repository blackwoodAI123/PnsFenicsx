{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciqQQdolViPh"
      },
      "source": [
        "# Install dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xRmmBUpfVN4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65628463-0891-4d65-cbd9-3bf3ff229bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-18 13:49:12--  https://fem-on-colab.github.io/releases/fenicsx-install-release-real.sh\n",
            "Resolving fem-on-colab.github.io (fem-on-colab.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to fem-on-colab.github.io (fem-on-colab.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4339 (4.2K) [application/x-sh]\n",
            "Saving to: ‘/tmp/fenicsx-install.sh’\n",
            "\n",
            "\r/tmp/fenicsx-instal   0%[                    ]       0  --.-KB/s               \r/tmp/fenicsx-instal 100%[===================>]   4.24K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-18 13:49:12 (40.3 MB/s) - ‘/tmp/fenicsx-install.sh’ saved [4339/4339]\n",
            "\n",
            "+ INSTALL_PREFIX=/usr/local\n",
            "++ echo /usr/local\n",
            "++ awk -F/ '{print NF-1}'\n",
            "+ INSTALL_PREFIX_DEPTH=2\n",
            "+ PROJECT_NAME=fem-on-colab\n",
            "+ SHARE_PREFIX=/usr/local/share/fem-on-colab\n",
            "+ FENICSX_INSTALLED=/usr/local/share/fem-on-colab/fenicsx.installed\n",
            "+ [[ ! -f /usr/local/share/fem-on-colab/fenicsx.installed ]]\n",
            "+ PYBIND11_INSTALL_SCRIPT_PATH=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/1f62c6f6/releases/pybind11-install.sh\n",
            "+ [[ https://github.com/fem-on-colab/fem-on-colab.github.io/raw/1f62c6f6/releases/pybind11-install.sh == http* ]]\n",
            "+ PYBIND11_INSTALL_SCRIPT_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/1f62c6f6/releases/pybind11-install.sh\n",
            "+ PYBIND11_INSTALL_SCRIPT_PATH=/tmp/pybind11-install.sh\n",
            "+ [[ ! -f /tmp/pybind11-install.sh ]]\n",
            "+ wget https://github.com/fem-on-colab/fem-on-colab.github.io/raw/1f62c6f6/releases/pybind11-install.sh -O /tmp/pybind11-install.sh\n",
            "--2025-12-18 13:49:12--  https://github.com/fem-on-colab/fem-on-colab.github.io/raw/1f62c6f6/releases/pybind11-install.sh\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/1f62c6f688fc40670846c6d32f1e275f31337fe1/releases/pybind11-install.sh [following]\n",
            "--2025-12-18 13:49:13--  https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/1f62c6f688fc40670846c6d32f1e275f31337fe1/releases/pybind11-install.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1800 (1.8K) [text/plain]\n",
            "Saving to: ‘/tmp/pybind11-install.sh’\n",
            "\n",
            "/tmp/pybind11-insta 100%[===================>]   1.76K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-18 13:49:13 (18.8 MB/s) - ‘/tmp/pybind11-install.sh’ saved [1800/1800]\n",
            "\n",
            "+ source /tmp/pybind11-install.sh\n",
            "++ set -e\n",
            "++ set -x\n",
            "++ INSTALL_PREFIX=/usr/local\n",
            "+++ echo /usr/local\n",
            "+++ awk -F/ '{print NF-1}'\n",
            "++ INSTALL_PREFIX_DEPTH=2\n",
            "++ PROJECT_NAME=fem-on-colab\n",
            "++ SHARE_PREFIX=/usr/local/share/fem-on-colab\n",
            "++ PYBIND11_INSTALLED=/usr/local/share/fem-on-colab/pybind11.installed\n",
            "++ [[ ! -f /usr/local/share/fem-on-colab/pybind11.installed ]]\n",
            "++ MPI4PY_INSTALL_SCRIPT_PATH=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/7a1e7fa8/releases/mpi4py-install.sh\n",
            "++ [[ https://github.com/fem-on-colab/fem-on-colab.github.io/raw/7a1e7fa8/releases/mpi4py-install.sh == http* ]]\n",
            "++ MPI4PY_INSTALL_SCRIPT_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/7a1e7fa8/releases/mpi4py-install.sh\n",
            "++ MPI4PY_INSTALL_SCRIPT_PATH=/tmp/mpi4py-install.sh\n",
            "++ [[ ! -f /tmp/mpi4py-install.sh ]]\n",
            "++ wget https://github.com/fem-on-colab/fem-on-colab.github.io/raw/7a1e7fa8/releases/mpi4py-install.sh -O /tmp/mpi4py-install.sh\n",
            "--2025-12-18 13:49:13--  https://github.com/fem-on-colab/fem-on-colab.github.io/raw/7a1e7fa8/releases/mpi4py-install.sh\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/7a1e7fa825a7a0ca7ad0541d6abc466153eb8d15/releases/mpi4py-install.sh [following]\n",
            "--2025-12-18 13:49:13--  https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/7a1e7fa825a7a0ca7ad0541d6abc466153eb8d15/releases/mpi4py-install.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2583 (2.5K) [text/plain]\n",
            "Saving to: ‘/tmp/mpi4py-install.sh’\n",
            "\n",
            "/tmp/mpi4py-install 100%[===================>]   2.52K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-18 13:49:13 (27.2 MB/s) - ‘/tmp/mpi4py-install.sh’ saved [2583/2583]\n",
            "\n",
            "++ source /tmp/mpi4py-install.sh\n",
            "+++ set -e\n",
            "+++ set -x\n",
            "+++ INSTALL_PREFIX=/usr/local\n",
            "++++ echo /usr/local\n",
            "++++ awk -F/ '{print NF-1}'\n",
            "+++ INSTALL_PREFIX_DEPTH=2\n",
            "+++ PROJECT_NAME=fem-on-colab\n",
            "+++ SHARE_PREFIX=/usr/local/share/fem-on-colab\n",
            "+++ MPI4PY_INSTALLED=/usr/local/share/fem-on-colab/mpi4py.installed\n",
            "+++ [[ ! -f /usr/local/share/fem-on-colab/mpi4py.installed ]]\n",
            "+++ GCC_INSTALL_SCRIPT_PATH=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/5bc9e949/releases/gcc-install.sh\n",
            "+++ [[ https://github.com/fem-on-colab/fem-on-colab.github.io/raw/5bc9e949/releases/gcc-install.sh == http* ]]\n",
            "+++ GCC_INSTALL_SCRIPT_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/5bc9e949/releases/gcc-install.sh\n",
            "+++ GCC_INSTALL_SCRIPT_PATH=/tmp/gcc-install.sh\n",
            "+++ [[ ! -f /tmp/gcc-install.sh ]]\n",
            "+++ wget https://github.com/fem-on-colab/fem-on-colab.github.io/raw/5bc9e949/releases/gcc-install.sh -O /tmp/gcc-install.sh\n",
            "--2025-12-18 13:49:13--  https://github.com/fem-on-colab/fem-on-colab.github.io/raw/5bc9e949/releases/gcc-install.sh\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/5bc9e949c120f6479a4c44f2258c422517cb87aa/releases/gcc-install.sh [following]\n",
            "--2025-12-18 13:49:13--  https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/5bc9e949c120f6479a4c44f2258c422517cb87aa/releases/gcc-install.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8358 (8.2K) [text/plain]\n",
            "Saving to: ‘/tmp/gcc-install.sh’\n",
            "\n",
            "/tmp/gcc-install.sh 100%[===================>]   8.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-18 13:49:13 (75.5 MB/s) - ‘/tmp/gcc-install.sh’ saved [8358/8358]\n",
            "\n",
            "+++ source /tmp/gcc-install.sh\n",
            "++++ set -e\n",
            "++++ set -x\n",
            "++++ INSTALL_PREFIX=/usr/local\n",
            "+++++ echo /usr/local\n",
            "+++++ awk -F/ '{print NF-1}'\n",
            "++++ INSTALL_PREFIX_DEPTH=2\n",
            "++++ PROJECT_NAME=fem-on-colab\n",
            "++++ SHARE_PREFIX=/usr/local/share/fem-on-colab\n",
            "++++ GCC_INSTALLED=/usr/local/share/fem-on-colab/gcc.installed\n",
            "++++ [[ ! -L /usr/local/lib64 ]]\n",
            "++++ [[ -e /usr/local/lib64 ]]\n",
            "++++ ln -s /usr/local/lib /usr/local/lib64\n",
            "++++ [[ ! -L /usr/local/lib64 ]]\n",
            "++++ [[ ! -d /usr/local/lib64 ]]\n",
            "++++ [[ ! -f /usr/local/share/fem-on-colab/gcc.installed ]]\n",
            "++++ GCC_ARCHIVE_PATH=https://github.com/fem-on-colab/fem-on-colab/releases/download/gcc-20251107-062633-3ce8afd/gcc-install.tar.gz\n",
            "++++ [[ https://github.com/fem-on-colab/fem-on-colab/releases/download/gcc-20251107-062633-3ce8afd/gcc-install.tar.gz == http* ]]\n",
            "++++ GCC_ARCHIVE_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab/releases/download/gcc-20251107-062633-3ce8afd/gcc-install.tar.gz\n",
            "++++ GCC_ARCHIVE_PATH=/tmp/gcc-install.tar.gz\n",
            "++++ wget https://github.com/fem-on-colab/fem-on-colab/releases/download/gcc-20251107-062633-3ce8afd/gcc-install.tar.gz -O /tmp/gcc-install.tar.gz\n",
            "--2025-12-18 13:49:13--  https://github.com/fem-on-colab/fem-on-colab/releases/download/gcc-20251107-062633-3ce8afd/gcc-install.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/370599515/b087775b-c4e3-4a2e-83a7-5b7370214f4b?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A48%3A31Z&rscd=attachment%3B+filename%3Dgcc-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A48%3A26Z&ske=2025-12-18T14%3A48%3A31Z&sks=b&skv=2018-11-09&sig=kmjM3X7VBkOtg8hZX%2F0U6BeKZffd1V%2Ff4Q9jq65IzmQ%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2OTM1NCwibmJmIjoxNzY2MDY1NzU0LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.Iu8EDUKVX8WmD6WD1PuVjc6KQi2kQpWntVw_5Pxun5o&response-content-disposition=attachment%3B%20filename%3Dgcc-install.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-18 13:49:14--  https://release-assets.githubusercontent.com/github-production-release-asset/370599515/b087775b-c4e3-4a2e-83a7-5b7370214f4b?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A48%3A31Z&rscd=attachment%3B+filename%3Dgcc-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A48%3A26Z&ske=2025-12-18T14%3A48%3A31Z&sks=b&skv=2018-11-09&sig=kmjM3X7VBkOtg8hZX%2F0U6BeKZffd1V%2Ff4Q9jq65IzmQ%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2OTM1NCwibmJmIjoxNzY2MDY1NzU0LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.Iu8EDUKVX8WmD6WD1PuVjc6KQi2kQpWntVw_5Pxun5o&response-content-disposition=attachment%3B%20filename%3Dgcc-install.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 688030755 (656M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/gcc-install.tar.gz’\n",
            "\n",
            "/tmp/gcc-install.ta 100%[===================>] 656.16M  87.5MB/s    in 6.8s    \n",
            "\n",
            "2025-12-18 13:49:20 (96.2 MB/s) - ‘/tmp/gcc-install.tar.gz’ saved [688030755/688030755]\n",
            "\n",
            "++++ [[ /tmp/gcc-install.tar.gz != skip ]]\n",
            "++++ tar -xzf /tmp/gcc-install.tar.gz --strip-components=2 --directory=/usr/local\n",
            "++++ apt install -y -qq zlib1g-dev\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-2ubuntu9.2).\n",
            "zlib1g-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.\n",
            "++++ [[ /tmp/gcc-install.tar.gz != skip ]]\n",
            "++++ for LEGACY_GPP in /usr/bin/g++-*\n",
            "+++++ /usr/bin/g++-11 -dumpversion\n",
            "++++ LEGACY_GCC_VERSION=11\n",
            "++++ update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11 11\n",
            "update-alternatives: using /usr/bin/g++-11 to provide /usr/bin/g++ (g++) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 11\n",
            "update-alternatives: using /usr/bin/gcc-11 to provide /usr/bin/gcc (gcc) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/gcc-ar gcc-ar /usr/bin/gcc-ar-11 11\n",
            "update-alternatives: using /usr/bin/gcc-ar-11 to provide /usr/bin/gcc-ar (gcc-ar) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/gcc-nm gcc-nm /usr/bin/gcc-nm-11 11\n",
            "update-alternatives: using /usr/bin/gcc-nm-11 to provide /usr/bin/gcc-nm (gcc-nm) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/gcc-ranlib gcc-ranlib /usr/bin/gcc-ranlib-11 11\n",
            "update-alternatives: using /usr/bin/gcc-ranlib-11 to provide /usr/bin/gcc-ranlib (gcc-ranlib) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/x86_64-linux-gnu-g++ x86_64-linux-gnu-g++ /usr/bin/x86_64-linux-gnu-g++-11 11\n",
            "update-alternatives: using /usr/bin/x86_64-linux-gnu-g++-11 to provide /usr/bin/x86_64-linux-gnu-g++ (x86_64-linux-gnu-g++) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/x86_64-linux-gnu-gcc x86_64-linux-gnu-gcc /usr/bin/x86_64-linux-gnu-gcc-11 11\n",
            "update-alternatives: using /usr/bin/x86_64-linux-gnu-gcc-11 to provide /usr/bin/x86_64-linux-gnu-gcc (x86_64-linux-gnu-gcc) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/x86_64-linux-gnu-gcc-ar x86_64-linux-gnu-gcc-ar /usr/bin/x86_64-linux-gnu-gcc-ar-11 11\n",
            "update-alternatives: using /usr/bin/x86_64-linux-gnu-gcc-ar-11 to provide /usr/bin/x86_64-linux-gnu-gcc-ar (x86_64-linux-gnu-gcc-ar) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/x86_64-linux-gnu-gcc-nm x86_64-linux-gnu-gcc-nm /usr/bin/x86_64-linux-gnu-gcc-nm-11 11\n",
            "update-alternatives: using /usr/bin/x86_64-linux-gnu-gcc-nm-11 to provide /usr/bin/x86_64-linux-gnu-gcc-nm (x86_64-linux-gnu-gcc-nm) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/x86_64-linux-gnu-gcc-ranlib x86_64-linux-gnu-gcc-ranlib /usr/bin/x86_64-linux-gnu-gcc-ranlib-11 11\n",
            "update-alternatives: using /usr/bin/x86_64-linux-gnu-gcc-ranlib-11 to provide /usr/bin/x86_64-linux-gnu-gcc-ranlib (x86_64-linux-gnu-gcc-ranlib) in auto mode\n",
            "+++++ /usr/local/bin/g++ -dumpversion\n",
            "++++ GCC_VERSION=12\n",
            "++++ update-alternatives --install /usr/bin/g++ g++ /usr/local/bin/g++-12 12\n",
            "update-alternatives: using /usr/local/bin/g++-12 to provide /usr/bin/g++ (g++) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/gcc gcc /usr/local/bin/gcc-12 12\n",
            "update-alternatives: using /usr/local/bin/gcc-12 to provide /usr/bin/gcc (gcc) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/gcc-ar gcc-ar /usr/local/bin/gcc-ar-12 12\n",
            "update-alternatives: using /usr/local/bin/gcc-ar-12 to provide /usr/bin/gcc-ar (gcc-ar) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/gcc-nm gcc-nm /usr/local/bin/gcc-nm-12 12\n",
            "update-alternatives: using /usr/local/bin/gcc-nm-12 to provide /usr/bin/gcc-nm (gcc-nm) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/gcc-ranlib gcc-ranlib /usr/local/bin/gcc-ranlib-12 12\n",
            "update-alternatives: using /usr/local/bin/gcc-ranlib-12 to provide /usr/bin/gcc-ranlib (gcc-ranlib) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/gfortran gfortran /usr/local/bin/gfortran-12 12\n",
            "update-alternatives: using /usr/local/bin/gfortran-12 to provide /usr/bin/gfortran (gfortran) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/x86_64-linux-gnu-g++ x86_64-linux-gnu-g++ /usr/local/bin/x86_64-linux-gnu-g++-12 12\n",
            "update-alternatives: using /usr/local/bin/x86_64-linux-gnu-g++-12 to provide /usr/bin/x86_64-linux-gnu-g++ (x86_64-linux-gnu-g++) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/x86_64-linux-gnu-gcc x86_64-linux-gnu-gcc /usr/local/bin/x86_64-linux-gnu-gcc-12 12\n",
            "update-alternatives: using /usr/local/bin/x86_64-linux-gnu-gcc-12 to provide /usr/bin/x86_64-linux-gnu-gcc (x86_64-linux-gnu-gcc) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/x86_64-linux-gnu-gcc-ar x86_64-linux-gnu-gcc-ar /usr/local/bin/x86_64-linux-gnu-gcc-ar-12 12\n",
            "update-alternatives: using /usr/local/bin/x86_64-linux-gnu-gcc-ar-12 to provide /usr/bin/x86_64-linux-gnu-gcc-ar (x86_64-linux-gnu-gcc-ar) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/x86_64-linux-gnu-gcc-nm x86_64-linux-gnu-gcc-nm /usr/local/bin/x86_64-linux-gnu-gcc-nm-12 12\n",
            "update-alternatives: using /usr/local/bin/x86_64-linux-gnu-gcc-nm-12 to provide /usr/bin/x86_64-linux-gnu-gcc-nm (x86_64-linux-gnu-gcc-nm) in auto mode\n",
            "++++ update-alternatives --install /usr/bin/x86_64-linux-gnu-gcc-ranlib x86_64-linux-gnu-gcc-ranlib /usr/local/bin/x86_64-linux-gnu-gcc-ranlib-12 12\n",
            "update-alternatives: using /usr/local/bin/x86_64-linux-gnu-gcc-ranlib-12 to provide /usr/bin/x86_64-linux-gnu-gcc-ranlib (x86_64-linux-gnu-gcc-ranlib) in auto mode\n",
            "++++ update-alternatives --set g++ /usr/local/bin/g++-12\n",
            "++++ update-alternatives --set gcc /usr/local/bin/gcc-12\n",
            "++++ update-alternatives --set gcc-ar /usr/local/bin/gcc-ar-12\n",
            "++++ update-alternatives --set gcc-nm /usr/local/bin/gcc-nm-12\n",
            "++++ update-alternatives --set gcc-ranlib /usr/local/bin/gcc-ranlib-12\n",
            "++++ update-alternatives --set gfortran /usr/local/bin/gfortran-12\n",
            "++++ update-alternatives --set x86_64-linux-gnu-g++ /usr/local/bin/x86_64-linux-gnu-g++-12\n",
            "++++ update-alternatives --set x86_64-linux-gnu-gcc /usr/local/bin/x86_64-linux-gnu-gcc-12\n",
            "++++ update-alternatives --set x86_64-linux-gnu-gcc-ar /usr/local/bin/x86_64-linux-gnu-gcc-ar-12\n",
            "++++ update-alternatives --set x86_64-linux-gnu-gcc-nm /usr/local/bin/x86_64-linux-gnu-gcc-nm-12\n",
            "++++ update-alternatives --set x86_64-linux-gnu-gcc-ranlib /usr/local/bin/x86_64-linux-gnu-gcc-ranlib-12\n",
            "++++ [[ /tmp/gcc-install.tar.gz != skip ]]\n",
            "+++++ which python3\n",
            "++++ PYTHON_EXEC=/usr/bin/python3\n",
            "+++++ dirname /usr/bin/python3\n",
            "++++ PYTHON_EXEC_DIR=/usr/bin\n",
            "+++++ objdump -x /usr/bin/python3\n",
            "+++++ sed 's| ||g'\n",
            "+++++ grep 'R.*PATH'\n",
            "+++++ sed 's|R.*PATH||g'\n",
            "+++++ sed 's|$ORIGIN|/usr/bin|g'\n",
            "++++ PYTHON_RPATH=\n",
            "++++ [[ -z '' ]]\n",
            "++++ PYTHON_RPATH=/usr/lib/x86_64-linux-gnu\n",
            "++++ INSTALL_PREFIX_RPATH=/usr/local/lib\n",
            "++++ [[ -L /usr/lib/x86_64-linux-gnu/libstdc++.so ]]\n",
            "+++++ basename /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.30\n",
            "++++ LIBSTDCXX_SYSTEM_VERSION=libstdc++.so.6.0.30\n",
            "+++++ basename /usr/local/lib/libstdc++.so.6.0.30 /usr/local/lib/libstdc++.so.6.0.30-gdb.py\n",
            "++++ LIBSTDCXX_INSTALL_PREFIX_VERSION=libstdc++.so.6.0.30\n",
            "++++ [[ libstdc++.so.6.0.30 != \\l\\i\\b\\s\\t\\d\\c\\+\\+\\.\\s\\o\\.\\6\\.\\0\\.\\3\\0 ]]\n",
            "++++ mkdir -p /usr/local/share/fem-on-colab\n",
            "++++ touch /usr/local/share/fem-on-colab/gcc.installed\n",
            "+++ MPI4PY_ARCHIVE_PATH=https://github.com/fem-on-colab/fem-on-colab/releases/download/mpi4py-20251107-064919-3ce8afd/mpi4py-install.tar.gz\n",
            "+++ [[ https://github.com/fem-on-colab/fem-on-colab/releases/download/mpi4py-20251107-064919-3ce8afd/mpi4py-install.tar.gz == http* ]]\n",
            "+++ MPI4PY_ARCHIVE_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab/releases/download/mpi4py-20251107-064919-3ce8afd/mpi4py-install.tar.gz\n",
            "+++ MPI4PY_ARCHIVE_PATH=/tmp/mpi4py-install.tar.gz\n",
            "+++ wget https://github.com/fem-on-colab/fem-on-colab/releases/download/mpi4py-20251107-064919-3ce8afd/mpi4py-install.tar.gz -O /tmp/mpi4py-install.tar.gz\n",
            "--2025-12-18 13:49:46--  https://github.com/fem-on-colab/fem-on-colab/releases/download/mpi4py-20251107-064919-3ce8afd/mpi4py-install.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/370599515/88f829fd-26e1-4c11-977d-ffbfc50846af?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A23%3A14Z&rscd=attachment%3B+filename%3Dmpi4py-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A22%3A20Z&ske=2025-12-18T14%3A23%3A14Z&sks=b&skv=2018-11-09&sig=Ysvcq%2F3wx3z6mXwC2OtlKm2j6%2FTER2mpNxrkMvUDicE%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2NzU4NywibmJmIjoxNzY2MDY1Nzg3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.UQ2r91v_DC_KLf2s6bshVrFZf_7DPM70Vue7sdRkeqg&response-content-disposition=attachment%3B%20filename%3Dmpi4py-install.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-18 13:49:47--  https://release-assets.githubusercontent.com/github-production-release-asset/370599515/88f829fd-26e1-4c11-977d-ffbfc50846af?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A23%3A14Z&rscd=attachment%3B+filename%3Dmpi4py-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A22%3A20Z&ske=2025-12-18T14%3A23%3A14Z&sks=b&skv=2018-11-09&sig=Ysvcq%2F3wx3z6mXwC2OtlKm2j6%2FTER2mpNxrkMvUDicE%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2NzU4NywibmJmIjoxNzY2MDY1Nzg3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.UQ2r91v_DC_KLf2s6bshVrFZf_7DPM70Vue7sdRkeqg&response-content-disposition=attachment%3B%20filename%3Dmpi4py-install.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14180426 (14M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/mpi4py-install.tar.gz’\n",
            "\n",
            "/tmp/mpi4py-install 100%[===================>]  13.52M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-18 13:49:47 (106 MB/s) - ‘/tmp/mpi4py-install.tar.gz’ saved [14180426/14180426]\n",
            "\n",
            "+++ [[ /tmp/mpi4py-install.tar.gz != skip ]]\n",
            "+++ tar -xzf /tmp/mpi4py-install.tar.gz --strip-components=2 --directory=/usr/local\n",
            "+++ [[ /tmp/mpi4py-install.tar.gz != skip ]]\n",
            "+++ command -v mpicc\n",
            "/usr/local/bin/mpicc\n",
            "+++ [[ /tmp/mpi4py-install.tar.gz != skip ]]\n",
            "+++ MPI_LIBS=('libhwloc*.so*' 'libmpi*.so*' 'libopen-pal*.so*' 'libpmix*.so*' 'libprrte*.so*')\n",
            "+++ for MPI_LIB in \"${MPI_LIBS[@]}\"\n",
            "+++ rm -f '/usr/lib/libhwloc*.so*'\n",
            "+++ rm -f /usr/lib/x86_64-linux-gnu/libhwloc.so /usr/lib/x86_64-linux-gnu/libhwloc.so.15 /usr/lib/x86_64-linux-gnu/libhwloc.so.15.5.2\n",
            "+++ ln -fs /usr/local/lib/libhwloc.so /usr/local/lib/libhwloc.so.15 /usr/local/lib/libhwloc.so.15.5.3 /usr/local/lib/libhwloc.so.15.8.1 /usr/lib\n",
            "+++ for MPI_LIB in \"${MPI_LIBS[@]}\"\n",
            "+++ rm -f '/usr/lib/libmpi*.so*'\n",
            "+++ rm -f /usr/lib/x86_64-linux-gnu/libmpi_cxx.so /usr/lib/x86_64-linux-gnu/libmpi_cxx.so.40 /usr/lib/x86_64-linux-gnu/libmpi_cxx.so.40.30.1 /usr/lib/x86_64-linux-gnu/libmpi_java.so /usr/lib/x86_64-linux-gnu/libmpi_java.so.40 /usr/lib/x86_64-linux-gnu/libmpi_java.so.40.30.0 /usr/lib/x86_64-linux-gnu/libmpi_mpifh-gfortran.so /usr/lib/x86_64-linux-gnu/libmpi_mpifh-gfortran.so.40 /usr/lib/x86_64-linux-gnu/libmpi_mpifh-gfortran.so.40.30.0 /usr/lib/x86_64-linux-gnu/libmpi_mpifh.so /usr/lib/x86_64-linux-gnu/libmpi_mpifh.so.40 /usr/lib/x86_64-linux-gnu/libmpi_mpifh.so.40.30.0 /usr/lib/x86_64-linux-gnu/libmpiseq_seq-5.4.0.so /usr/lib/x86_64-linux-gnu/libmpiseq_seq-5.4.so /usr/lib/x86_64-linux-gnu/libmpiseq_seq.so /usr/lib/x86_64-linux-gnu/libmpi++.so /usr/lib/x86_64-linux-gnu/libmpi.so /usr/lib/x86_64-linux-gnu/libmpi.so.40 /usr/lib/x86_64-linux-gnu/libmpi.so.40.30.2 /usr/lib/x86_64-linux-gnu/libmpi_usempif08-gfortran.so /usr/lib/x86_64-linux-gnu/libmpi_usempif08-gfortran.so.40 /usr/lib/x86_64-linux-gnu/libmpi_usempif08-gfortran.so.40.30.0 /usr/lib/x86_64-linux-gnu/libmpi_usempif08.so /usr/lib/x86_64-linux-gnu/libmpi_usempif08.so.40 /usr/lib/x86_64-linux-gnu/libmpi_usempif08.so.40.30.0 /usr/lib/x86_64-linux-gnu/libmpi_usempi_ignore_tkr-gfortran.so /usr/lib/x86_64-linux-gnu/libmpi_usempi_ignore_tkr-gfortran.so.40 /usr/lib/x86_64-linux-gnu/libmpi_usempi_ignore_tkr-gfortran.so.40.30.0 /usr/lib/x86_64-linux-gnu/libmpi_usempi_ignore_tkr.so /usr/lib/x86_64-linux-gnu/libmpi_usempi_ignore_tkr.so.40 /usr/lib/x86_64-linux-gnu/libmpi_usempi_ignore_tkr.so.40.30.0\n",
            "+++ ln -fs /usr/local/lib/libmpi_mpifh.so /usr/local/lib/libmpi_mpifh.so.40 /usr/local/lib/libmpi_mpifh.so.40.40.1 /usr/local/lib/libmpi.so /usr/local/lib/libmpi.so.40 /usr/local/lib/libmpi.so.40.40.7 /usr/local/lib/libmpi_usempif08.so /usr/local/lib/libmpi_usempif08.so.40 /usr/local/lib/libmpi_usempif08.so.40.40.3 /usr/local/lib/libmpi_usempi_ignore_tkr.so /usr/local/lib/libmpi_usempi_ignore_tkr.so.40 /usr/local/lib/libmpi_usempi_ignore_tkr.so.40.40.1 /usr/lib\n",
            "+++ for MPI_LIB in \"${MPI_LIBS[@]}\"\n",
            "+++ rm -f '/usr/lib/libopen-pal*.so*'\n",
            "+++ rm -f /usr/lib/x86_64-linux-gnu/libopen-pal.so /usr/lib/x86_64-linux-gnu/libopen-pal.so.40 /usr/lib/x86_64-linux-gnu/libopen-pal.so.40.30.2\n",
            "+++ ln -fs /usr/local/lib/libopen-pal.so /usr/local/lib/libopen-pal.so.80 /usr/local/lib/libopen-pal.so.80.0.5 /usr/lib\n",
            "+++ for MPI_LIB in \"${MPI_LIBS[@]}\"\n",
            "+++ rm -f '/usr/lib/libpmix*.so*'\n",
            "+++ rm -f /usr/lib/x86_64-linux-gnu/libpmix.so /usr/lib/x86_64-linux-gnu/libpmix.so.2 /usr/lib/x86_64-linux-gnu/libpmix.so.2.5.2\n",
            "+++ ln -fs /usr/local/lib/libpmix.so /usr/local/lib/libpmix.so.2 /usr/local/lib/libpmix.so.2.13.9 /usr/lib\n",
            "+++ for MPI_LIB in \"${MPI_LIBS[@]}\"\n",
            "+++ rm -f '/usr/lib/libprrte*.so*'\n",
            "+++ rm -f '/usr/lib/x86_64-linux-gnu/libprrte*.so*'\n",
            "+++ ln -fs /usr/local/lib/libprrte.so /usr/local/lib/libprrte.so.3 /usr/local/lib/libprrte.so.3.0.12 /usr/lib\n",
            "+++ mkdir -p /usr/local/share/fem-on-colab\n",
            "+++ touch /usr/local/share/fem-on-colab/mpi4py.installed\n",
            "++ PYBIND11_ARCHIVE_PATH=https://github.com/fem-on-colab/fem-on-colab/releases/download/pybind11-20251107-070642-3ce8afd/pybind11-install.tar.gz\n",
            "++ [[ https://github.com/fem-on-colab/fem-on-colab/releases/download/pybind11-20251107-070642-3ce8afd/pybind11-install.tar.gz == http* ]]\n",
            "++ PYBIND11_ARCHIVE_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab/releases/download/pybind11-20251107-070642-3ce8afd/pybind11-install.tar.gz\n",
            "++ PYBIND11_ARCHIVE_PATH=/tmp/pybind11-install.tar.gz\n",
            "++ wget https://github.com/fem-on-colab/fem-on-colab/releases/download/pybind11-20251107-070642-3ce8afd/pybind11-install.tar.gz -O /tmp/pybind11-install.tar.gz\n",
            "--2025-12-18 13:49:47--  https://github.com/fem-on-colab/fem-on-colab/releases/download/pybind11-20251107-070642-3ce8afd/pybind11-install.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/370599515/22a87a64-0212-4f81-be7d-0fac6154c4be?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A24%3A06Z&rscd=attachment%3B+filename%3Dpybind11-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A23%3A13Z&ske=2025-12-18T14%3A24%3A06Z&sks=b&skv=2018-11-09&sig=FsCUINNd9BS5QTbf8OXTsxwTfyoRw5Mr2mHJdiXv9xU%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2NjA4NywibmJmIjoxNzY2MDY1Nzg3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.H1JfWkLm5Da5d9k6SyF01sF4TPE1z5FwjARsdLUyhFQ&response-content-disposition=attachment%3B%20filename%3Dpybind11-install.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-18 13:49:47--  https://release-assets.githubusercontent.com/github-production-release-asset/370599515/22a87a64-0212-4f81-be7d-0fac6154c4be?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A24%3A06Z&rscd=attachment%3B+filename%3Dpybind11-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A23%3A13Z&ske=2025-12-18T14%3A24%3A06Z&sks=b&skv=2018-11-09&sig=FsCUINNd9BS5QTbf8OXTsxwTfyoRw5Mr2mHJdiXv9xU%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2NjA4NywibmJmIjoxNzY2MDY1Nzg3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.H1JfWkLm5Da5d9k6SyF01sF4TPE1z5FwjARsdLUyhFQ&response-content-disposition=attachment%3B%20filename%3Dpybind11-install.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 743406 (726K) [application/octet-stream]\n",
            "Saving to: ‘/tmp/pybind11-install.tar.gz’\n",
            "\n",
            "/tmp/pybind11-insta 100%[===================>] 725.98K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-12-18 13:49:47 (14.4 MB/s) - ‘/tmp/pybind11-install.tar.gz’ saved [743406/743406]\n",
            "\n",
            "++ [[ /tmp/pybind11-install.tar.gz != skip ]]\n",
            "++ rm -rf '/usr/lib/python*/*-packages/pybind11*'\n",
            "++ rm -rf '/usr/local/lib/python*/*-packages/pybind11*'\n",
            "++ tar -xzf /tmp/pybind11-install.tar.gz --strip-components=2 --directory=/usr/local\n",
            "++ mkdir -p /usr/local/share/fem-on-colab\n",
            "++ touch /usr/local/share/fem-on-colab/pybind11.installed\n",
            "+ BOOST_INSTALL_SCRIPT_PATH=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/d4424d38/releases/boost-install.sh\n",
            "+ [[ https://github.com/fem-on-colab/fem-on-colab.github.io/raw/d4424d38/releases/boost-install.sh == http* ]]\n",
            "+ BOOST_INSTALL_SCRIPT_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/d4424d38/releases/boost-install.sh\n",
            "+ BOOST_INSTALL_SCRIPT_PATH=/tmp/boost-install.sh\n",
            "+ [[ ! -f /tmp/boost-install.sh ]]\n",
            "+ wget https://github.com/fem-on-colab/fem-on-colab.github.io/raw/d4424d38/releases/boost-install.sh -O /tmp/boost-install.sh\n",
            "--2025-12-18 13:49:48--  https://github.com/fem-on-colab/fem-on-colab.github.io/raw/d4424d38/releases/boost-install.sh\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/d4424d38a9618179efe32120b4725422b9e8c7b4/releases/boost-install.sh [following]\n",
            "--2025-12-18 13:49:48--  https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/d4424d38a9618179efe32120b4725422b9e8c7b4/releases/boost-install.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1856 (1.8K) [text/plain]\n",
            "Saving to: ‘/tmp/boost-install.sh’\n",
            "\n",
            "/tmp/boost-install. 100%[===================>]   1.81K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-18 13:49:48 (24.9 MB/s) - ‘/tmp/boost-install.sh’ saved [1856/1856]\n",
            "\n",
            "+ source /tmp/boost-install.sh\n",
            "++ set -e\n",
            "++ set -x\n",
            "++ INSTALL_PREFIX=/usr/local\n",
            "+++ echo /usr/local\n",
            "+++ awk -F/ '{print NF-1}'\n",
            "++ INSTALL_PREFIX_DEPTH=2\n",
            "++ PROJECT_NAME=fem-on-colab\n",
            "++ SHARE_PREFIX=/usr/local/share/fem-on-colab\n",
            "++ BOOST_INSTALLED=/usr/local/share/fem-on-colab/boost.installed\n",
            "++ [[ ! -f /usr/local/share/fem-on-colab/boost.installed ]]\n",
            "++ GCC_INSTALL_SCRIPT_PATH=/tmp/gcc-install.sh\n",
            "++ [[ /tmp/gcc-install.sh == http* ]]\n",
            "++ source /tmp/gcc-install.sh\n",
            "+++ set -e\n",
            "+++ set -x\n",
            "+++ INSTALL_PREFIX=/usr/local\n",
            "++++ echo /usr/local\n",
            "++++ awk -F/ '{print NF-1}'\n",
            "+++ INSTALL_PREFIX_DEPTH=2\n",
            "+++ PROJECT_NAME=fem-on-colab\n",
            "+++ SHARE_PREFIX=/usr/local/share/fem-on-colab\n",
            "+++ GCC_INSTALLED=/usr/local/share/fem-on-colab/gcc.installed\n",
            "+++ [[ ! -L /usr/local/lib64 ]]\n",
            "+++ [[ ! -L /usr/local/lib64 ]]\n",
            "+++ [[ ! -d /usr/local/lib64 ]]\n",
            "+++ [[ ! -f /usr/local/share/fem-on-colab/gcc.installed ]]\n",
            "++ BOOST_ARCHIVE_PATH=https://github.com/fem-on-colab/fem-on-colab/releases/download/boost-20251107-064917-3ce8afd/boost-install.tar.gz\n",
            "++ [[ https://github.com/fem-on-colab/fem-on-colab/releases/download/boost-20251107-064917-3ce8afd/boost-install.tar.gz == http* ]]\n",
            "++ BOOST_ARCHIVE_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab/releases/download/boost-20251107-064917-3ce8afd/boost-install.tar.gz\n",
            "++ BOOST_ARCHIVE_PATH=/tmp/boost-install.tar.gz\n",
            "++ wget https://github.com/fem-on-colab/fem-on-colab/releases/download/boost-20251107-064917-3ce8afd/boost-install.tar.gz -O /tmp/boost-install.tar.gz\n",
            "--2025-12-18 13:49:48--  https://github.com/fem-on-colab/fem-on-colab/releases/download/boost-20251107-064917-3ce8afd/boost-install.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/370599515/7967f050-97b7-41c3-8c26-6e039c0ecc2c?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A48%3A59Z&rscd=attachment%3B+filename%3Dboost-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A48%3A12Z&ske=2025-12-18T14%3A48%3A59Z&sks=b&skv=2018-11-09&sig=SLwDxAr0EqPTCnoDYWPMk67evmPadTJ7KRSHlKxXxQI%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2NzU4OCwibmJmIjoxNzY2MDY1Nzg4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.hi3V5NuOGC6m5p2fA_vQVSoEoNDIIhmuNw-5kP2hEjs&response-content-disposition=attachment%3B%20filename%3Dboost-install.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-18 13:49:48--  https://release-assets.githubusercontent.com/github-production-release-asset/370599515/7967f050-97b7-41c3-8c26-6e039c0ecc2c?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A48%3A59Z&rscd=attachment%3B+filename%3Dboost-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A48%3A12Z&ske=2025-12-18T14%3A48%3A59Z&sks=b&skv=2018-11-09&sig=SLwDxAr0EqPTCnoDYWPMk67evmPadTJ7KRSHlKxXxQI%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2NzU4OCwibmJmIjoxNzY2MDY1Nzg4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.hi3V5NuOGC6m5p2fA_vQVSoEoNDIIhmuNw-5kP2hEjs&response-content-disposition=attachment%3B%20filename%3Dboost-install.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26884801 (26M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/boost-install.tar.gz’\n",
            "\n",
            "/tmp/boost-install. 100%[===================>]  25.64M   140MB/s    in 0.2s    \n",
            "\n",
            "2025-12-18 13:49:48 (140 MB/s) - ‘/tmp/boost-install.tar.gz’ saved [26884801/26884801]\n",
            "\n",
            "++ [[ /tmp/boost-install.tar.gz != skip ]]\n",
            "++ tar -xzf /tmp/boost-install.tar.gz --strip-components=2 --directory=/usr/local\n",
            "++ [[ /tmp/boost-install.tar.gz != skip ]]\n",
            "++ ln -fs /usr/local/lib/libboost_atomic.so /usr/local/lib/libboost_atomic.so.1.89.0 /usr/local/lib/libboost_charconv.so /usr/local/lib/libboost_charconv.so.1.89.0 /usr/local/lib/libboost_chrono.so /usr/local/lib/libboost_chrono.so.1.89.0 /usr/local/lib/libboost_container.so /usr/local/lib/libboost_container.so.1.89.0 /usr/local/lib/libboost_context.so /usr/local/lib/libboost_context.so.1.89.0 /usr/local/lib/libboost_contract.so /usr/local/lib/libboost_contract.so.1.89.0 /usr/local/lib/libboost_coroutine.so /usr/local/lib/libboost_coroutine.so.1.89.0 /usr/local/lib/libboost_date_time.so /usr/local/lib/libboost_date_time.so.1.89.0 /usr/local/lib/libboost_fiber.so /usr/local/lib/libboost_fiber.so.1.89.0 /usr/local/lib/libboost_filesystem.so /usr/local/lib/libboost_filesystem.so.1.89.0 /usr/local/lib/libboost_graph.so /usr/local/lib/libboost_graph.so.1.89.0 /usr/local/lib/libboost_iostreams.so /usr/local/lib/libboost_iostreams.so.1.89.0 /usr/local/lib/libboost_json.a /usr/local/lib/libboost_json.so /usr/local/lib/libboost_json.so.1.89.0 /usr/local/lib/libboost_log_setup.so /usr/local/lib/libboost_log_setup.so.1.89.0 /usr/local/lib/libboost_log.so /usr/local/lib/libboost_log.so.1.89.0 /usr/local/lib/libboost_math_c99f.so /usr/local/lib/libboost_math_c99f.so.1.89.0 /usr/local/lib/libboost_math_c99l.so /usr/local/lib/libboost_math_c99l.so.1.89.0 /usr/local/lib/libboost_math_c99.so /usr/local/lib/libboost_math_c99.so.1.89.0 /usr/local/lib/libboost_math_tr1f.so /usr/local/lib/libboost_math_tr1f.so.1.89.0 /usr/local/lib/libboost_math_tr1l.so /usr/local/lib/libboost_math_tr1l.so.1.89.0 /usr/local/lib/libboost_math_tr1.so /usr/local/lib/libboost_math_tr1.so.1.89.0 /usr/local/lib/libboost_nowide.so /usr/local/lib/libboost_nowide.so.1.89.0 /usr/local/lib/libboost_numpy312.so /usr/local/lib/libboost_numpy312.so.1.89.0 /usr/local/lib/libboost_prg_exec_monitor.so /usr/local/lib/libboost_prg_exec_monitor.so.1.89.0 /usr/local/lib/libboost_process.so /usr/local/lib/libboost_process.so.1.89.0 /usr/local/lib/libboost_program_options.so /usr/local/lib/libboost_program_options.so.1.89.0 /usr/local/lib/libboost_python312.so /usr/local/lib/libboost_python312.so.1.89.0 /usr/local/lib/libboost_random.so /usr/local/lib/libboost_random.so.1.89.0 /usr/local/lib/libboost_regex.so /usr/local/lib/libboost_regex.so.1.89.0 /usr/local/lib/libboost_serialization.so /usr/local/lib/libboost_serialization.so.1.89.0 /usr/local/lib/libboost_stacktrace_addr2line.so /usr/local/lib/libboost_stacktrace_addr2line.so.1.89.0 /usr/local/lib/libboost_stacktrace_basic.so /usr/local/lib/libboost_stacktrace_basic.so.1.89.0 /usr/local/lib/libboost_stacktrace_from_exception.so /usr/local/lib/libboost_stacktrace_from_exception.so.1.89.0 /usr/local/lib/libboost_stacktrace_noop.so /usr/local/lib/libboost_stacktrace_noop.so.1.89.0 /usr/local/lib/libboost_thread.so /usr/local/lib/libboost_thread.so.1.89.0 /usr/local/lib/libboost_timer.so /usr/local/lib/libboost_timer.so.1.89.0 /usr/local/lib/libboost_type_erasure.so /usr/local/lib/libboost_type_erasure.so.1.89.0 /usr/local/lib/libboost_unit_test_framework.so /usr/local/lib/libboost_unit_test_framework.so.1.89.0 /usr/local/lib/libboost_url.so /usr/local/lib/libboost_url.so.1.89.0 /usr/local/lib/libboost_wave.so /usr/local/lib/libboost_wave.so.1.89.0 /usr/local/lib/libboost_wserialization.so /usr/local/lib/libboost_wserialization.so.1.89.0 /usr/lib\n",
            "++ mkdir -p /usr/local/share/fem-on-colab\n",
            "++ touch /usr/local/share/fem-on-colab/boost.installed\n",
            "+ SLEPC4PY_INSTALL_SCRIPT_PATH=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/ae550130/releases/slepc4py-install-release-real.sh\n",
            "+ [[ https://github.com/fem-on-colab/fem-on-colab.github.io/raw/ae550130/releases/slepc4py-install-release-real.sh == http* ]]\n",
            "+ SLEPC4PY_INSTALL_SCRIPT_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/ae550130/releases/slepc4py-install-release-real.sh\n",
            "+ SLEPC4PY_INSTALL_SCRIPT_PATH=/tmp/slepc4py-install.sh\n",
            "+ [[ ! -f /tmp/slepc4py-install.sh ]]\n",
            "+ wget https://github.com/fem-on-colab/fem-on-colab.github.io/raw/ae550130/releases/slepc4py-install-release-real.sh -O /tmp/slepc4py-install.sh\n",
            "--2025-12-18 13:49:50--  https://github.com/fem-on-colab/fem-on-colab.github.io/raw/ae550130/releases/slepc4py-install-release-real.sh\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/ae55013078a827cc989ac8f7655708a8221e0f06/releases/slepc4py-install-release-real.sh [following]\n",
            "--2025-12-18 13:49:50--  https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/ae55013078a827cc989ac8f7655708a8221e0f06/releases/slepc4py-install-release-real.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1758 (1.7K) [text/plain]\n",
            "Saving to: ‘/tmp/slepc4py-install.sh’\n",
            "\n",
            "/tmp/slepc4py-insta 100%[===================>]   1.72K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-18 13:49:51 (25.4 MB/s) - ‘/tmp/slepc4py-install.sh’ saved [1758/1758]\n",
            "\n",
            "+ source /tmp/slepc4py-install.sh\n",
            "++ set -e\n",
            "++ set -x\n",
            "++ INSTALL_PREFIX=/usr/local\n",
            "+++ echo /usr/local\n",
            "+++ awk -F/ '{print NF-1}'\n",
            "++ INSTALL_PREFIX_DEPTH=2\n",
            "++ PROJECT_NAME=fem-on-colab\n",
            "++ SHARE_PREFIX=/usr/local/share/fem-on-colab\n",
            "++ SLEPC4PY_INSTALLED=/usr/local/share/fem-on-colab/slepc4py.installed\n",
            "++ [[ ! -f /usr/local/share/fem-on-colab/slepc4py.installed ]]\n",
            "++ PETSC4PY_INSTALL_SCRIPT_PATH=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/3eee5746/releases/petsc4py-install-release-real.sh\n",
            "++ [[ https://github.com/fem-on-colab/fem-on-colab.github.io/raw/3eee5746/releases/petsc4py-install-release-real.sh == http* ]]\n",
            "++ PETSC4PY_INSTALL_SCRIPT_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/3eee5746/releases/petsc4py-install-release-real.sh\n",
            "++ PETSC4PY_INSTALL_SCRIPT_PATH=/tmp/petsc4py-install.sh\n",
            "++ [[ ! -f /tmp/petsc4py-install.sh ]]\n",
            "++ wget https://github.com/fem-on-colab/fem-on-colab.github.io/raw/3eee5746/releases/petsc4py-install-release-real.sh -O /tmp/petsc4py-install.sh\n",
            "--2025-12-18 13:49:51--  https://github.com/fem-on-colab/fem-on-colab.github.io/raw/3eee5746/releases/petsc4py-install-release-real.sh\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/3eee5746f904f859fe454fb34e86219cf26aa59e/releases/petsc4py-install-release-real.sh [following]\n",
            "--2025-12-18 13:49:51--  https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/3eee5746f904f859fe454fb34e86219cf26aa59e/releases/petsc4py-install-release-real.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1802 (1.8K) [text/plain]\n",
            "Saving to: ‘/tmp/petsc4py-install.sh’\n",
            "\n",
            "/tmp/petsc4py-insta 100%[===================>]   1.76K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-18 13:49:51 (24.0 MB/s) - ‘/tmp/petsc4py-install.sh’ saved [1802/1802]\n",
            "\n",
            "++ source /tmp/petsc4py-install.sh\n",
            "+++ set -e\n",
            "+++ set -x\n",
            "+++ INSTALL_PREFIX=/usr/local\n",
            "++++ echo /usr/local\n",
            "++++ awk -F/ '{print NF-1}'\n",
            "+++ INSTALL_PREFIX_DEPTH=2\n",
            "+++ PROJECT_NAME=fem-on-colab\n",
            "+++ SHARE_PREFIX=/usr/local/share/fem-on-colab\n",
            "+++ PETSC4PY_INSTALLED=/usr/local/share/fem-on-colab/petsc4py.installed\n",
            "+++ [[ ! -f /usr/local/share/fem-on-colab/petsc4py.installed ]]\n",
            "+++ H5PY_INSTALL_SCRIPT_PATH=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/82a9dfcc/releases/h5py-install.sh\n",
            "+++ [[ https://github.com/fem-on-colab/fem-on-colab.github.io/raw/82a9dfcc/releases/h5py-install.sh == http* ]]\n",
            "+++ H5PY_INSTALL_SCRIPT_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/82a9dfcc/releases/h5py-install.sh\n",
            "+++ H5PY_INSTALL_SCRIPT_PATH=/tmp/h5py-install.sh\n",
            "+++ [[ ! -f /tmp/h5py-install.sh ]]\n",
            "+++ wget https://github.com/fem-on-colab/fem-on-colab.github.io/raw/82a9dfcc/releases/h5py-install.sh -O /tmp/h5py-install.sh\n",
            "--2025-12-18 13:49:51--  https://github.com/fem-on-colab/fem-on-colab.github.io/raw/82a9dfcc/releases/h5py-install.sh\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/82a9dfcc53c4abb67bd2fecc9a4e3100723d61a1/releases/h5py-install.sh [following]\n",
            "--2025-12-18 13:49:51--  https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/82a9dfcc53c4abb67bd2fecc9a4e3100723d61a1/releases/h5py-install.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1724 (1.7K) [text/plain]\n",
            "Saving to: ‘/tmp/h5py-install.sh’\n",
            "\n",
            "/tmp/h5py-install.s 100%[===================>]   1.68K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-18 13:49:51 (20.2 MB/s) - ‘/tmp/h5py-install.sh’ saved [1724/1724]\n",
            "\n",
            "+++ source /tmp/h5py-install.sh\n",
            "++++ set -e\n",
            "++++ set -x\n",
            "++++ INSTALL_PREFIX=/usr/local\n",
            "+++++ echo /usr/local\n",
            "+++++ awk -F/ '{print NF-1}'\n",
            "++++ INSTALL_PREFIX_DEPTH=2\n",
            "++++ PROJECT_NAME=fem-on-colab\n",
            "++++ SHARE_PREFIX=/usr/local/share/fem-on-colab\n",
            "++++ H5PY_INSTALLED=/usr/local/share/fem-on-colab/h5py.installed\n",
            "++++ [[ ! -f /usr/local/share/fem-on-colab/h5py.installed ]]\n",
            "++++ MPI4PY_INSTALL_SCRIPT_PATH=/tmp/mpi4py-install.sh\n",
            "++++ [[ /tmp/mpi4py-install.sh == http* ]]\n",
            "++++ source /tmp/mpi4py-install.sh\n",
            "+++++ set -e\n",
            "+++++ set -x\n",
            "+++++ INSTALL_PREFIX=/usr/local\n",
            "++++++ echo /usr/local\n",
            "++++++ awk -F/ '{print NF-1}'\n",
            "+++++ INSTALL_PREFIX_DEPTH=2\n",
            "+++++ PROJECT_NAME=fem-on-colab\n",
            "+++++ SHARE_PREFIX=/usr/local/share/fem-on-colab\n",
            "+++++ MPI4PY_INSTALLED=/usr/local/share/fem-on-colab/mpi4py.installed\n",
            "+++++ [[ ! -f /usr/local/share/fem-on-colab/mpi4py.installed ]]\n",
            "++++ H5PY_ARCHIVE_PATH=https://github.com/fem-on-colab/fem-on-colab/releases/download/h5py-20251107-070632-3ce8afd/h5py-install.tar.gz\n",
            "++++ [[ https://github.com/fem-on-colab/fem-on-colab/releases/download/h5py-20251107-070632-3ce8afd/h5py-install.tar.gz == http* ]]\n",
            "++++ H5PY_ARCHIVE_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab/releases/download/h5py-20251107-070632-3ce8afd/h5py-install.tar.gz\n",
            "++++ H5PY_ARCHIVE_PATH=/tmp/h5py-install.tar.gz\n",
            "++++ wget https://github.com/fem-on-colab/fem-on-colab/releases/download/h5py-20251107-070632-3ce8afd/h5py-install.tar.gz -O /tmp/h5py-install.tar.gz\n",
            "--2025-12-18 13:49:51--  https://github.com/fem-on-colab/fem-on-colab/releases/download/h5py-20251107-070632-3ce8afd/h5py-install.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/370599515/c9559fc4-3e0a-4e0d-bf79-2e5dcad79c56?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A23%3A38Z&rscd=attachment%3B+filename%3Dh5py-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A23%3A15Z&ske=2025-12-18T14%3A23%3A38Z&sks=b&skv=2018-11-09&sig=jvhg%2BPvwp0wGWXKsDrWt3f%2BdhzUfNRd5jaoxt2iuufo%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2NzU5MiwibmJmIjoxNzY2MDY1NzkyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ._wgo9j4gXkd60uraqjuMPvauiKm72kdIGNawmou14z8&response-content-disposition=attachment%3B%20filename%3Dh5py-install.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-18 13:49:52--  https://release-assets.githubusercontent.com/github-production-release-asset/370599515/c9559fc4-3e0a-4e0d-bf79-2e5dcad79c56?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A23%3A38Z&rscd=attachment%3B+filename%3Dh5py-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A23%3A15Z&ske=2025-12-18T14%3A23%3A38Z&sks=b&skv=2018-11-09&sig=jvhg%2BPvwp0wGWXKsDrWt3f%2BdhzUfNRd5jaoxt2iuufo%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2NzU5MiwibmJmIjoxNzY2MDY1NzkyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ._wgo9j4gXkd60uraqjuMPvauiKm72kdIGNawmou14z8&response-content-disposition=attachment%3B%20filename%3Dh5py-install.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14970080 (14M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/h5py-install.tar.gz’\n",
            "\n",
            "/tmp/h5py-install.t 100%[===================>]  14.28M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-18 13:49:52 (111 MB/s) - ‘/tmp/h5py-install.tar.gz’ saved [14970080/14970080]\n",
            "\n",
            "++++ [[ /tmp/h5py-install.tar.gz != skip ]]\n",
            "++++ rm -rf '/usr/lib/python*/*-packages/h5py*'\n",
            "++++ rm -rf /usr/local/lib/python3.12/dist-packages/h5py /usr/local/lib/python3.12/dist-packages/h5py-3.15.1.dist-info /usr/local/lib/python3.12/dist-packages/h5py.libs\n",
            "++++ tar -xzf /tmp/h5py-install.tar.gz --strip-components=2 --directory=/usr/local\n",
            "++++ mkdir -p /usr/local/share/fem-on-colab\n",
            "++++ touch /usr/local/share/fem-on-colab/h5py.installed\n",
            "+++ apt install -y -qq libblas-dev liblapack-dev\n",
            "liblapack-dev is already the newest version (3.10.0-2ubuntu1).\n",
            "Suggested packages:\n",
            "  liblapack-doc\n",
            "The following NEW packages will be installed:\n",
            "  libblas-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 1 not upgraded.\n",
            "Need to get 164 kB of archives.\n",
            "After this operation, 1,084 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libblas-dev:amd64.\n",
            "(Reading database ... 117528 files and directories currently installed.)\n",
            "Preparing to unpack .../libblas-dev_3.10.0-2ubuntu1_amd64.deb ...\n",
            "Unpacking libblas-dev:amd64 (3.10.0-2ubuntu1) ...\n",
            "Setting up libblas-dev:amd64 (3.10.0-2ubuntu1) ...\n",
            "+++ PETSC4PY_ARCHIVE_PATH=https://github.com/fem-on-colab/fem-on-colab/releases/download/petsc4py-20251107-072039-3ce8afd-release-real/petsc4py-install.tar.gz\n",
            "+++ [[ https://github.com/fem-on-colab/fem-on-colab/releases/download/petsc4py-20251107-072039-3ce8afd-release-real/petsc4py-install.tar.gz == http* ]]\n",
            "+++ PETSC4PY_ARCHIVE_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab/releases/download/petsc4py-20251107-072039-3ce8afd-release-real/petsc4py-install.tar.gz\n",
            "+++ PETSC4PY_ARCHIVE_PATH=/tmp/petsc4py-install.tar.gz\n",
            "+++ wget https://github.com/fem-on-colab/fem-on-colab/releases/download/petsc4py-20251107-072039-3ce8afd-release-real/petsc4py-install.tar.gz -O /tmp/petsc4py-install.tar.gz\n",
            "--2025-12-18 13:50:00--  https://github.com/fem-on-colab/fem-on-colab/releases/download/petsc4py-20251107-072039-3ce8afd-release-real/petsc4py-install.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/370599515/eab46ffb-2d02-4f5e-8173-9e51273d2646?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A47%3A36Z&rscd=attachment%3B+filename%3Dpetsc4py-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A47%3A22Z&ske=2025-12-18T14%3A47%3A36Z&sks=b&skv=2018-11-09&sig=LY5eJo99Kmt7qfOt1looj7xdu4DsPepSiJGITZPzzbU%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2OTQwMCwibmJmIjoxNzY2MDY1ODAwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.iTK1MIZKTt22tIzq6ytHWxnSrdMMBvMGCH8VONisoFk&response-content-disposition=attachment%3B%20filename%3Dpetsc4py-install.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-18 13:50:00--  https://release-assets.githubusercontent.com/github-production-release-asset/370599515/eab46ffb-2d02-4f5e-8173-9e51273d2646?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A47%3A36Z&rscd=attachment%3B+filename%3Dpetsc4py-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A47%3A22Z&ske=2025-12-18T14%3A47%3A36Z&sks=b&skv=2018-11-09&sig=LY5eJo99Kmt7qfOt1looj7xdu4DsPepSiJGITZPzzbU%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2OTQwMCwibmJmIjoxNzY2MDY1ODAwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.iTK1MIZKTt22tIzq6ytHWxnSrdMMBvMGCH8VONisoFk&response-content-disposition=attachment%3B%20filename%3Dpetsc4py-install.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169000319 (161M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/petsc4py-install.tar.gz’\n",
            "\n",
            "/tmp/petsc4py-insta 100%[===================>] 161.17M   196MB/s    in 0.8s    \n",
            "\n",
            "2025-12-18 13:50:01 (196 MB/s) - ‘/tmp/petsc4py-install.tar.gz’ saved [169000319/169000319]\n",
            "\n",
            "+++ [[ /tmp/petsc4py-install.tar.gz != skip ]]\n",
            "+++ tar -xzf /tmp/petsc4py-install.tar.gz --strip-components=2 --directory=/usr/local\n",
            "+++ mkdir -p /usr/local/share/fem-on-colab\n",
            "+++ touch /usr/local/share/fem-on-colab/petsc4py.installed\n",
            "++ SLEPC4PY_ARCHIVE_PATH=https://github.com/fem-on-colab/fem-on-colab/releases/download/slepc4py-20251107-081256-3ce8afd-release-real/slepc4py-install.tar.gz\n",
            "++ [[ https://github.com/fem-on-colab/fem-on-colab/releases/download/slepc4py-20251107-081256-3ce8afd-release-real/slepc4py-install.tar.gz == http* ]]\n",
            "++ SLEPC4PY_ARCHIVE_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab/releases/download/slepc4py-20251107-081256-3ce8afd-release-real/slepc4py-install.tar.gz\n",
            "++ SLEPC4PY_ARCHIVE_PATH=/tmp/slepc4py-install.tar.gz\n",
            "++ wget https://github.com/fem-on-colab/fem-on-colab/releases/download/slepc4py-20251107-081256-3ce8afd-release-real/slepc4py-install.tar.gz -O /tmp/slepc4py-install.tar.gz\n",
            "--2025-12-18 13:50:07--  https://github.com/fem-on-colab/fem-on-colab/releases/download/slepc4py-20251107-081256-3ce8afd-release-real/slepc4py-install.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/370599515/192ce37a-ab27-41e3-94ef-a60c05efdf10?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A47%3A41Z&rscd=attachment%3B+filename%3Dslepc4py-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A47%3A13Z&ske=2025-12-18T14%3A47%3A41Z&sks=b&skv=2018-11-09&sig=YvnLlo2F6ob95dgEMk69VnS4ya1BmbitQGS6Z3A%2BkI0%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2NzYwNywibmJmIjoxNzY2MDY1ODA3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.O_MKefIYtVrbRIA89Ou06adwTPqDqta_ymEtOehBu4k&response-content-disposition=attachment%3B%20filename%3Dslepc4py-install.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-18 13:50:07--  https://release-assets.githubusercontent.com/github-production-release-asset/370599515/192ce37a-ab27-41e3-94ef-a60c05efdf10?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A47%3A41Z&rscd=attachment%3B+filename%3Dslepc4py-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A47%3A13Z&ske=2025-12-18T14%3A47%3A41Z&sks=b&skv=2018-11-09&sig=YvnLlo2F6ob95dgEMk69VnS4ya1BmbitQGS6Z3A%2BkI0%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2NzYwNywibmJmIjoxNzY2MDY1ODA3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.O_MKefIYtVrbRIA89Ou06adwTPqDqta_ymEtOehBu4k&response-content-disposition=attachment%3B%20filename%3Dslepc4py-install.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23835918 (23M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/slepc4py-install.tar.gz’\n",
            "\n",
            "/tmp/slepc4py-insta 100%[===================>]  22.73M   132MB/s    in 0.2s    \n",
            "\n",
            "2025-12-18 13:50:07 (132 MB/s) - ‘/tmp/slepc4py-install.tar.gz’ saved [23835918/23835918]\n",
            "\n",
            "++ [[ /tmp/slepc4py-install.tar.gz != skip ]]\n",
            "++ tar -xzf /tmp/slepc4py-install.tar.gz --strip-components=2 --directory=/usr/local\n",
            "++ mkdir -p /usr/local/share/fem-on-colab\n",
            "++ touch /usr/local/share/fem-on-colab/slepc4py.installed\n",
            "+ VTK_INSTALL_SCRIPT_PATH=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/95ef1728/releases/vtk-install.sh\n",
            "+ [[ https://github.com/fem-on-colab/fem-on-colab.github.io/raw/95ef1728/releases/vtk-install.sh == http* ]]\n",
            "+ VTK_INSTALL_SCRIPT_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab.github.io/raw/95ef1728/releases/vtk-install.sh\n",
            "+ VTK_INSTALL_SCRIPT_PATH=/tmp/vtk-install.sh\n",
            "+ [[ ! -f /tmp/vtk-install.sh ]]\n",
            "+ wget https://github.com/fem-on-colab/fem-on-colab.github.io/raw/95ef1728/releases/vtk-install.sh -O /tmp/vtk-install.sh\n",
            "--2025-12-18 13:50:08--  https://github.com/fem-on-colab/fem-on-colab.github.io/raw/95ef1728/releases/vtk-install.sh\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/95ef1728d8ff4903ec85684f2410995240a86f9a/releases/vtk-install.sh [following]\n",
            "--2025-12-18 13:50:08--  https://raw.githubusercontent.com/fem-on-colab/fem-on-colab.github.io/95ef1728d8ff4903ec85684f2410995240a86f9a/releases/vtk-install.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1699 (1.7K) [text/plain]\n",
            "Saving to: ‘/tmp/vtk-install.sh’\n",
            "\n",
            "/tmp/vtk-install.sh 100%[===================>]   1.66K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-18 13:50:08 (8.17 MB/s) - ‘/tmp/vtk-install.sh’ saved [1699/1699]\n",
            "\n",
            "+ source /tmp/vtk-install.sh\n",
            "++ set -e\n",
            "++ set -x\n",
            "++ INSTALL_PREFIX=/usr/local\n",
            "+++ echo /usr/local\n",
            "+++ awk -F/ '{print NF-1}'\n",
            "++ INSTALL_PREFIX_DEPTH=2\n",
            "++ PROJECT_NAME=fem-on-colab\n",
            "++ SHARE_PREFIX=/usr/local/share/fem-on-colab\n",
            "++ VTK_INSTALLED=/usr/local/share/fem-on-colab/vtk.installed\n",
            "++ [[ ! -f /usr/local/share/fem-on-colab/vtk.installed ]]\n",
            "++ H5PY_INSTALL_SCRIPT_PATH=/tmp/h5py-install.sh\n",
            "++ [[ /tmp/h5py-install.sh == http* ]]\n",
            "++ source /tmp/h5py-install.sh\n",
            "+++ set -e\n",
            "+++ set -x\n",
            "+++ INSTALL_PREFIX=/usr/local\n",
            "++++ echo /usr/local\n",
            "++++ awk -F/ '{print NF-1}'\n",
            "+++ INSTALL_PREFIX_DEPTH=2\n",
            "+++ PROJECT_NAME=fem-on-colab\n",
            "+++ SHARE_PREFIX=/usr/local/share/fem-on-colab\n",
            "+++ H5PY_INSTALLED=/usr/local/share/fem-on-colab/h5py.installed\n",
            "+++ [[ ! -f /usr/local/share/fem-on-colab/h5py.installed ]]\n",
            "++ VTK_ARCHIVE_PATH=https://github.com/fem-on-colab/fem-on-colab/releases/download/vtk-20251107-072047-3ce8afd/vtk-install.tar.gz\n",
            "++ [[ https://github.com/fem-on-colab/fem-on-colab/releases/download/vtk-20251107-072047-3ce8afd/vtk-install.tar.gz == http* ]]\n",
            "++ VTK_ARCHIVE_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab/releases/download/vtk-20251107-072047-3ce8afd/vtk-install.tar.gz\n",
            "++ VTK_ARCHIVE_PATH=/tmp/vtk-install.tar.gz\n",
            "++ wget https://github.com/fem-on-colab/fem-on-colab/releases/download/vtk-20251107-072047-3ce8afd/vtk-install.tar.gz -O /tmp/vtk-install.tar.gz\n",
            "--2025-12-18 13:50:08--  https://github.com/fem-on-colab/fem-on-colab/releases/download/vtk-20251107-072047-3ce8afd/vtk-install.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/370599515/4581a654-de3d-4f7a-b496-360d82762a56?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A47%3A56Z&rscd=attachment%3B+filename%3Dvtk-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A47%3A24Z&ske=2025-12-18T14%3A47%3A56Z&sks=b&skv=2018-11-09&sig=5Cw163PDaIAoR5RJ5jYvNG8jI345txEIrGU3NmfnSBE%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2OTQwOCwibmJmIjoxNzY2MDY1ODA4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.7wtehmRDc64f6YsuCjsCimPz31lcj5SQbXlzSNmwhXw&response-content-disposition=attachment%3B%20filename%3Dvtk-install.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-18 13:50:08--  https://release-assets.githubusercontent.com/github-production-release-asset/370599515/4581a654-de3d-4f7a-b496-360d82762a56?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A47%3A56Z&rscd=attachment%3B+filename%3Dvtk-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A47%3A24Z&ske=2025-12-18T14%3A47%3A56Z&sks=b&skv=2018-11-09&sig=5Cw163PDaIAoR5RJ5jYvNG8jI345txEIrGU3NmfnSBE%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2OTQwOCwibmJmIjoxNzY2MDY1ODA4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.7wtehmRDc64f6YsuCjsCimPz31lcj5SQbXlzSNmwhXw&response-content-disposition=attachment%3B%20filename%3Dvtk-install.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 128495582 (123M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/vtk-install.tar.gz’\n",
            "\n",
            "/tmp/vtk-install.ta 100%[===================>] 122.54M   121MB/s    in 1.0s    \n",
            "\n",
            "2025-12-18 13:50:10 (121 MB/s) - ‘/tmp/vtk-install.tar.gz’ saved [128495582/128495582]\n",
            "\n",
            "++ [[ /tmp/vtk-install.tar.gz != skip ]]\n",
            "++ tar -xzf /tmp/vtk-install.tar.gz --strip-components=2 --directory=/usr/local\n",
            "++ apt install -y -qq libgl1-mesa-dev libxrender1 xvfb\n",
            "libxrender1 is already the newest version (1:0.9.10-1build4).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.16).\n",
            "The following additional packages will be installed:\n",
            "  libegl-dev libgl-dev libgles-dev libgles1 libglvnd-core-dev libglvnd-dev\n",
            "  libglx-dev libopengl-dev\n",
            "The following NEW packages will be installed:\n",
            "  libegl-dev libgl-dev libgl1-mesa-dev libgles-dev libgles1 libglvnd-core-dev\n",
            "  libglvnd-dev libglx-dev libopengl-dev\n",
            "0 upgraded, 9 newly installed, 0 to remove and 1 not upgraded.\n",
            "Need to get 221 kB of archives.\n",
            "After this operation, 2,577 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "(Reading database ... 117538 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../1-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../2-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../3-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../4-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../5-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../6-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../7-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../8-libgl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "++ mkdir -p /usr/local/share/fem-on-colab\n",
            "++ touch /usr/local/share/fem-on-colab/vtk.installed\n",
            "+ FENICSX_ARCHIVE_PATH=https://github.com/fem-on-colab/fem-on-colab/releases/download/fenicsx-20251129-010224-717225a-release-real/fenicsx-install.tar.gz\n",
            "+ [[ https://github.com/fem-on-colab/fem-on-colab/releases/download/fenicsx-20251129-010224-717225a-release-real/fenicsx-install.tar.gz == http* ]]\n",
            "+ FENICSX_ARCHIVE_DOWNLOAD=https://github.com/fem-on-colab/fem-on-colab/releases/download/fenicsx-20251129-010224-717225a-release-real/fenicsx-install.tar.gz\n",
            "+ FENICSX_ARCHIVE_PATH=/tmp/fenicsx-install.tar.gz\n",
            "+ wget https://github.com/fem-on-colab/fem-on-colab/releases/download/fenicsx-20251129-010224-717225a-release-real/fenicsx-install.tar.gz -O /tmp/fenicsx-install.tar.gz\n",
            "--2025-12-18 13:50:27--  https://github.com/fem-on-colab/fem-on-colab/releases/download/fenicsx-20251129-010224-717225a-release-real/fenicsx-install.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/370599515/8e9beb5e-6310-4ba1-afa9-58210371baed?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A47%3A08Z&rscd=attachment%3B+filename%3Dfenicsx-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A46%3A34Z&ske=2025-12-18T14%3A47%3A08Z&sks=b&skv=2018-11-09&sig=5H8hdA2uWIWUVOPB3dFUkRzoJF3pz4OVJpwtW%2F58mqM%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2NzYyOCwibmJmIjoxNzY2MDY1ODI4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.RvJGSXjezP_1y919kSXxrTzAM0uPCV1v-Hz_THC5t_w&response-content-disposition=attachment%3B%20filename%3Dfenicsx-install.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-18 13:50:28--  https://release-assets.githubusercontent.com/github-production-release-asset/370599515/8e9beb5e-6310-4ba1-afa9-58210371baed?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-18T14%3A47%3A08Z&rscd=attachment%3B+filename%3Dfenicsx-install.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-18T13%3A46%3A34Z&ske=2025-12-18T14%3A47%3A08Z&sks=b&skv=2018-11-09&sig=5H8hdA2uWIWUVOPB3dFUkRzoJF3pz4OVJpwtW%2F58mqM%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjA2NzYyOCwibmJmIjoxNzY2MDY1ODI4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.RvJGSXjezP_1y919kSXxrTzAM0uPCV1v-Hz_THC5t_w&response-content-disposition=attachment%3B%20filename%3Dfenicsx-install.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23521056 (22M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/fenicsx-install.tar.gz’\n",
            "\n",
            "/tmp/fenicsx-instal 100%[===================>]  22.43M  82.0MB/s    in 0.3s    \n",
            "\n",
            "2025-12-18 13:50:28 (82.0 MB/s) - ‘/tmp/fenicsx-install.tar.gz’ saved [23521056/23521056]\n",
            "\n",
            "+ [[ /tmp/fenicsx-install.tar.gz != skip ]]\n",
            "+ tar -xzf /tmp/fenicsx-install.tar.gz --strip-components=2 --directory=/usr/local\n",
            "+ mkdir -p /usr/local/share/fem-on-colab\n",
            "+ touch /usr/local/share/fem-on-colab/fenicsx.installed\n",
            "+ set +x\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "################################################################################\n",
            "#     This installation is offered by FEM on Colab, an open-source project     #\n",
            "#       developed and maintained at Università Cattolica del Sacro Cuore       #\n",
            "#   by Prof. Francesco Ballarin. Please see https://fem-on-colab.github.io/    #\n",
            "#       for more details, including a list of further available packages       #\n",
            "#       and how to sponsor the development or contribute to the project.       #\n",
            "#                                                                              #\n",
            "#   We are conducting an informal survey on FEM on Colab usage by our users.   #\n",
            "#   The survey is anonymous, and its compilation will typically only require   #\n",
            "#   a couple of minutes of your time. If you wish, give us your feedback at    #\n",
            "#                     https://forms.gle/36sZZWNvPpUv8XWr7                      #\n",
            "################################################################################\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import dolfinx\n",
        "except ImportError:\n",
        "    !wget \"https://fem-on-colab.github.io/releases/fenicsx-install-release-real.sh\" -O \"/tmp/fenicsx-install.sh\" && bash \"/tmp/fenicsx-install.sh\"\n",
        "    import dolfinx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tYuOeO0376mV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5e7b6b-cfe5-4179-83ca-da371967f544"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c7b282f8-e89b-446a-9b87-28635f44ea2d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c7b282f8-e89b-446a-9b87-28635f44ea2d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving polyhedral_splines.zip to polyhedral_splines.zip\n",
            "Archive:  polyhedral_splines.zip\n",
            "   creating: polyhedral_splines/polyhedral_splines/\n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/config  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/description  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/HEAD  \n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/hooks/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/commit-msg.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/post-update.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/pre-commit.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/pre-merge-commit.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/pre-push.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/pre-rebase.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/pre-receive.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/push-to-checkout.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/sendemail-validate.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/hooks/update.sample  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/index  \n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/info/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/info/exclude  \n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/logs/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/logs/HEAD  \n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/logs/refs/\n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/logs/refs/heads/\n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/logs/refs/heads/feature/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/logs/refs/heads/feature/lagrange  \n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/logs/refs/remotes/\n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/logs/refs/remotes/origin/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/logs/refs/remotes/origin/HEAD  \n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/objects/\n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/objects/info/\n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/objects/pack/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/objects/pack/pack-37dc782463ee4612b11c83de2c92a60998fb5769.idx  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/objects/pack/pack-37dc782463ee4612b11c83de2c92a60998fb5769.pack  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/objects/pack/pack-37dc782463ee4612b11c83de2c92a60998fb5769.rev  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/packed-refs  \n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/refs/\n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/refs/heads/\n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/refs/heads/feature/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/refs/heads/feature/lagrange  \n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/refs/remotes/\n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/refs/remotes/origin/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/.git/refs/remotes/origin/HEAD  \n",
            "   creating: polyhedral_splines/polyhedral_splines/.git/refs/tags/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/.gitignore  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/bitbucket-pipelines.yml  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/CMakeLists.txt  \n",
            "   creating: polyhedral_splines/polyhedral_splines/csharp/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/csharp/csBindings.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/csharp/PolyhedralNetSplines.cs  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/csharp/PolyhedralNetSplines.csproj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/csharp/README.md  \n",
            "   creating: polyhedral_splines/polyhedral_splines/Doc/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/Doxyfile  \n",
            "   creating: polyhedral_splines/polyhedral_splines/Doc/extras/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/extras/footer.html  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/extras/logo_align.css  \n",
            "   creating: polyhedral_splines/polyhedral_splines/Doc/images/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/images/allowable_config_1.png  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/images/allowable_config_2.png  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/images/allowable_config_pns3.png  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/images/irregular.png  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/images/subd_compare.jpg  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/images/surflab_logo_ll.png  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/images/surflab_logo_ll_175x55.png  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/images/tesla_color_patches.jpg  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/images/tesla_compare.jpg  \n",
            "   creating: polyhedral_splines/polyhedral_splines/Doc/pages/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/pages/compile.md  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/pages/cpp_lib.md  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/pages/cpp_lib_compile.md  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/pages/c_sharp_compile.md  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/pages/c_sharp_lib.md  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/pages/exe.md  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/pages/getting_started.md  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/pages/mainpage.md  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/pages/python_compile.md  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/pages/web.md  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/Doc/pages/web_compile.md  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/index.html  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/LICENSE  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/pyproject.toml  \n",
            "   creating: polyhedral_splines/polyhedral_splines/python/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/python/CMakeLists.txt  \n",
            "   creating: polyhedral_splines/polyhedral_splines/python/polyhedral_net_splines/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/python/polyhedral_net_splines/__init__.py  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/python/pybind.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/python/README.md  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/README.md  \n",
            "   creating: polyhedral_splines/polyhedral_splines/src/\n",
            "   creating: polyhedral_splines/polyhedral_splines/src/api/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/api/PnSPatch.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/api/PnSPatch_impl.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/api/PnSPatch_impl.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/api/PnSpline.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/api/PnSpline_impl.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/api/PnSpline_impl.hpp  \n",
            "   creating: polyhedral_splines/polyhedral_splines/src/Helper/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Helper/HalfedgeOperation.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Helper/HalfedgeOperation.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Helper/Helper.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Helper/Helper.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Helper/Matrix.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Helper/ReadCSV2Matrix.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Helper/ReadCSV2Matrix.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Helper/simple_arg.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/main.cpp  \n",
            "   creating: polyhedral_splines/polyhedral_splines/src/Patch/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/ExtraordinaryPatchConstructor.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/ExtraordinaryPatchConstructor.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/NGonPatchConstructor.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/NGonPatchConstructor.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Patch.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Patch.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/PatchBuilder.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/PatchBuilder.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/PatchConstructor.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/PolarPatchConstructor.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/PolarPatchConstructor.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/RegularPatchConstructor.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/RegularPatchConstructor.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/T0PatchConstructor.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/T0PatchConstructor.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/T1PatchConstructor.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/T1PatchConstructor.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/T2PatchConstructor.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/T2PatchConstructor.hpp  \n",
            "   creating: polyhedral_splines/polyhedral_splines/src/Patch/Table/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/eopSct3.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/eopSct5.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/eopSct6.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/eopSct7.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/eopSct8.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/lagrange.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/LICENSE.txt  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/ngonSct3.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/ngonSct5.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/ngonSct6.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/ngonSct7.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/ngonSct8.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/polarSct3.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/polarSct4.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/polarSct5.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/polarSct6.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/polarSct7.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/polarSct8.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/T0.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/T1.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/Table/T2.csv  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/TwoTrianglesTwoQuadsPatchConstructor.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Patch/TwoTrianglesTwoQuadsPatchConstructor.hpp  \n",
            "   creating: polyhedral_splines/polyhedral_splines/src/PatchConsumer/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/PatchConsumer/BVWriter.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/PatchConsumer/BVWriter.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/PatchConsumer/EvaluatedMeshWriter.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/PatchConsumer/EvaluatedMeshWriter.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/PatchConsumer/IGSWriter.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/PatchConsumer/IGSWriter.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/PatchConsumer/PatchConsumer.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/PatchConsumer/STEPWriter.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/PatchConsumer/STEPWriter.hpp  \n",
            "   creating: polyhedral_splines/polyhedral_splines/src/Pool/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Pool/Pool.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/ProcessMesh.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/ProcessMesh.hpp  \n",
            "   creating: polyhedral_splines/polyhedral_splines/src/Subdivision/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Subdivision/subdivision.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Subdivision/subdivision.hpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Subdivision/VertexMapping.cpp  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/src/Subdivision/VertexMapping.hpp  \n",
            "   creating: polyhedral_splines/polyhedral_splines/testfile/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/airplane.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/cube.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/cylinder.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/eop3sct.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/eop5sct.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/eop6sct.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/eop7sct.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/eop8sct.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/hand.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/ngon3.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/ngon5.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/ngon6.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/ngon7.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/ngon8.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/opener.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/plane2x2.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/polar3sct.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/polar4sct.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/polar5sct.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/polar6sct.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/polar7sct.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/polar8sct.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/suzanne_all_configurations.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/T0.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/T012.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/T1.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/T2.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/tee.obj  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/testfile/tricube.obj  \n",
            "   creating: polyhedral_splines/polyhedral_splines/wasm/\n",
            "  inflating: polyhedral_splines/polyhedral_splines/wasm/README.md  \n",
            "  inflating: polyhedral_splines/polyhedral_splines/wasm/wasmBindings.cpp  \n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.12/dist-packages (3.31.10)\n",
            "/content/polyhedral_splines/polyhedral_splines\n",
            "Processing /content/polyhedral_splines/polyhedral_splines\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: polyhedral_net_splines\n",
            "  Building wheel for polyhedral_net_splines (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyhedral_net_splines: filename=polyhedral_net_splines-0.1.0-cp312-cp312-linux_x86_64.whl size=1092918 sha256=e4eb5f90bcfb073267bfe98dba38614b84c13364750f02bf8fb317de7fa915a4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o2xbg3ym/wheels/77/84/92/e79fbaa3d603b21a7d08d017e40a05ec993ea4c246c0c7ffb9\n",
            "Successfully built polyhedral_net_splines\n",
            "Installing collected packages: polyhedral_net_splines\n",
            "Successfully installed polyhedral_net_splines-0.1.0\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import polyhedral_net_splines as pns\n",
        "except ImportError:\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  !unzip polyhedral_splines.zip -d polyhedral_splines\n",
        "  !pip install cmake\n",
        "  !rm -rf polyhedral_splines.zip\n",
        "  %cd polyhedral_splines/polyhedral_splines\n",
        "  !pip install .\n",
        "  %cd ../..\n",
        "  import polyhedral_net_splines as pns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IS08aphY1Eo"
      },
      "outputs": [],
      "source": [
        "import dolfinx\n",
        "import basix\n",
        "import ufl\n",
        "from mpi4py import MPI\n",
        "from dolfinx.fem.petsc import LinearProblem\n",
        "import numpy\n",
        "import numpy as np\n",
        "import pyvista as pv\n",
        "import inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "054Gd6LLqw_3"
      },
      "outputs": [],
      "source": [
        "from mpi4py import MPI\n",
        "from petsc4py import PETSc\n",
        "\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm.autonotebook\n",
        "\n",
        "from pyvista import examples\n",
        "import imageio\n",
        "\n",
        "\n",
        "import basix\n",
        "from basix import CellType, ElementFamily, LagrangeVariant, SobolevSpace\n",
        "from basix.ufl import element\n",
        "\n",
        "import ufl\n",
        "from ufl import (FacetNormal, Identity, Measure, TestFunction, TrialFunction,\n",
        "                 as_vector, div, dot, ds, dx, inner, lhs, grad,\n",
        "                 nabla_grad, rhs, sym, system, SpatialCoordinate)\n",
        "\n",
        "from dolfinx import mesh, io, plot, fem\n",
        "from dolfinx.mesh import (create_unit_square, CellType as DFXCellType,\n",
        "                          create_unit_interval, create_mesh,\n",
        "                          meshtags_from_entities, create_unit_cube, create_box)\n",
        "from dolfinx.cpp.mesh import to_type, cell_entity_type\n",
        "from dolfinx.cpp.io import perm_gmsh\n",
        "\n",
        "from dolfinx.fem import (Constant, Function, functionspace,\n",
        "                         assemble_scalar, dirichletbc, form,\n",
        "                         locate_dofs_geometrical, locate_dofs_topological,\n",
        "                         set_bc)\n",
        "from dolfinx.fem.petsc import (apply_lifting, assemble_matrix,\n",
        "                               assemble_vector, create_vector,\n",
        "                               create_matrix, set_bc)\n",
        "from dolfinx.nls.petsc import NewtonSolver\n",
        "from dolfinx.io import (VTXWriter, XDMFFile, distribute_entity_data)\n",
        "from dolfinx.io import gmsh as dfx_gmesh\n",
        "from dolfinx.plot import vtk_mesh\n",
        "from dolfinx.graph import adjacencylist\n",
        "from dolfinx.geometry import (bb_tree, compute_collisions_points,\n",
        "                              compute_colliding_cells)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJzqNJJah3Nj"
      },
      "source": [
        "# PNS FEM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN9TIHwBp9Vo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4644f232-c747-44ae-c262-3f5616807b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:344: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:344: SyntaxWarning: invalid escape sequence '\\ '\n",
            "/tmp/ipython-input-3266781016.py:344: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  Solves problems of the form :math:`F(u, v) = 0 \\ \\forall v \\in V` using\n"
          ]
        }
      ],
      "source": [
        "import typing\n",
        "from petsc4py import PETSc\n",
        "import dolfinx.fem.petsc\n",
        "from dolfinx.fem.petsc import assemble_matrix, assemble_vector, create_matrix, _create_form, create_vector\n",
        "import itertools\n",
        "import functools\n",
        "from mpi4py import MPI\n",
        "import ufl\n",
        "import numpy as np\n",
        "import polyhedral_net_splines as pns\n",
        "import basix\n",
        "from tqdm import tqdm\n",
        "\n",
        "import time\n",
        "from functools import wraps\n",
        "from contextlib import contextmanager\n",
        "\n",
        "from dolfinx.fem import extract_function_spaces\n",
        "\n",
        "# Store total times\n",
        "total_times = {}\n",
        "\n",
        "# Thread-local (or global) exclusion time store\n",
        "_excluded_time = {}\n",
        "\n",
        "@contextmanager\n",
        "def exclude_time():\n",
        "    thread_id = 'default'  # In real multi-threaded code, use threading.get_ident()\n",
        "    start = time.perf_counter()\n",
        "    yield\n",
        "    end = time.perf_counter()\n",
        "    _excluded_time[thread_id] = _excluded_time.get(thread_id, 0) + (end - start)\n",
        "\n",
        "def track_time(func):\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        thread_id = 'default'\n",
        "        _excluded_time[thread_id] = 0  # Reset before each call\n",
        "        start = time.perf_counter()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.perf_counter()\n",
        "        elapsed = end - start - _excluded_time[thread_id]\n",
        "        total_times[func.__name__] = total_times.get(func.__name__, 0) + elapsed\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "cubicLagrangeDofOrder = [0, 6, 7, 2, 4, 12, 14, 10, 5, 13, 15, 11, 1, 8, 9, 3]\n",
        "cubicLagrangeDofOrderInv = [0, 12, 3, 15, 4, 8, 1, 2, 13, 14, 7, 11, 5, 9, 6, 10]\n",
        "\n",
        "def assemble_prolongation_matrix(pnsObject) -> PETSc.Mat:\n",
        "    \"\"\"Construct Prolongation matrix of size (numBBcoeffs, numPnsCP)\n",
        "\n",
        "    Args:\n",
        "        pnsObject: PNS object\n",
        "\n",
        "    Returns:\n",
        "        Prolongation matrix\n",
        "    \"\"\"\n",
        "    comm = pnsObject['comm']\n",
        "    numBB = pnsObject['numPatches'] * 16\n",
        "    numPns = pnsObject['numVerts']\n",
        "    numElements = pnsObject['numElements']\n",
        "\n",
        "    K = PETSc.Mat().createAIJ(size=(numBB*numElements, numPns*numElements), comm=comm)\n",
        "    K.setUp()\n",
        "    currCp = 0\n",
        "    for pb in pnsObject['augmentedLagrangePatchBuilders']:\n",
        "        neighborhood = pb.neighbor_verts\n",
        "        mask = pb.mask\n",
        "        for maskIdx in range(len(mask)):\n",
        "            rowIdx = (maskIdx//16)*16 + cubicLagrangeDofOrderInv[maskIdx % 16]\n",
        "            cpRow = mask[rowIdx]\n",
        "            u, inv = np.unique(neighborhood, return_inverse=True)\n",
        "            coeffs = dict(zip(u, np.bincount(inv, weights=cpRow)))\n",
        "            for neighbor in coeffs:\n",
        "                for e in range(numElements):\n",
        "                    writeRow = e*16 + currCp\n",
        "                    writeCol = e + numElements * neighbor\n",
        "                    K[writeRow, writeCol] = coeffs[neighbor]\n",
        "            if maskIdx % 16 == 15:\n",
        "                currCp += (numElements-1)*16\n",
        "            currCp += 1\n",
        "    K.assemble()\n",
        "    return K\n",
        "\n",
        "\n",
        "def fix_zero_rows(mat: PETSc.Mat):\n",
        "    \"\"\"For any all-zero row in PETSc Mat, set the diagonal to 1.\"\"\"\n",
        "    nrows, _ = mat.getSize()\n",
        "    zero_rows = []\n",
        "    for i in range(nrows):\n",
        "        # Get row entries\n",
        "        cols, vals = mat.getRow(i)\n",
        "        if cols.size == 0 or all(abs(v) < 1e-14 for v in vals):\n",
        "            zero_rows.append(i)\n",
        "    mat.zeroRowsColumns(zero_rows, diag = 1)\n",
        "    mat.assemble()\n",
        "    return mat\n",
        "\n",
        "@track_time\n",
        "def assemble_matrix_pns(pnsObject, a, bc = None, lagrange_bcs=[], result = None, A = None, AK = None, KTAK = None):\n",
        "    \"\"\"Assemble bilinear form into a matrix for PNS.\n",
        "    Args:\n",
        "        pnsObject: PNS object\n",
        "        a: Bilinear UFL form or a sequence of sequence of bilinear\n",
        "            forms, the left hand side of the variational problem.\n",
        "        bc: Dirichlet boundary condition with PNS DOF.\n",
        "        lagrange_bcs: Lagrange basis Dirichlet boundary conditions.\n",
        "        result: Optional Matrix to assemble the bilinear form into.\n",
        "        A: Bilinear form matrix in Lagrange basis\n",
        "        AK: Bilinear form matrix in Lagrange basis\n",
        "        KTAK: Temprory as setting to result directly without copy not working.\n",
        "    Returns:\n",
        "        Bilinear form matrix for PNS.\n",
        "        Bilinear form matrix in Lagrange basis(no BC)\n",
        "    \"\"\"\n",
        "    comm = pnsObject['comm']\n",
        "\n",
        "    with exclude_time():\n",
        "        if A is None:\n",
        "            A = create_matrix(a)\n",
        "        # A.assemble()\n",
        "        A.zeroEntries()\n",
        "        A = dolfinx.fem.petsc.assemble_matrix(A, a, bcs=lagrange_bcs)\n",
        "        A.assemble()\n",
        "    K = pnsObject['prolongation_matrix']\n",
        "    AK = A.matMult(K, result=AK)\n",
        "    KTAK = K.transposeMatMult(AK, result = KTAK) # for some reason cannot set directly to result when result is used with non-linear solver.\n",
        "    if bc is not None:\n",
        "        bc.setMatrix(KTAK)\n",
        "    KTAK.assemble()\n",
        "    KTAK = fix_zero_rows(KTAK)\n",
        "    if result is not None:\n",
        "        result.assemble()\n",
        "        KTAK.copy(result)\n",
        "    return KTAK, A\n",
        "\n",
        "@track_time\n",
        "def assemble_vector_pns(pnsObject, L, A = None, bc = None, lagrange_bcs=[], bilinear_form=None, result = None, u_func_for_lifting=None, alpha=1.0, b = None): # Renamed x0 to u_func_for_lifting\n",
        "    \"\"\"Assemble linear form into a vector for PNS.\n",
        "    Args:\n",
        "        pnsObject: PNS object\n",
        "        L: Linear UFL form or a sequence of linear forms, the right\n",
        "            hand side of the variational problem.\n",
        "        A: Bilinear form matrix in Lagrange basis\n",
        "        bc: Dirichlet boundary condition with PNS DOF.\n",
        "        lagrange_bcs: Lagrange basis Dirichlet boundary conditions.\n",
        "        bilinear_form: Bilinear form in Lagrange basis. Required if applying lagrange bcs.\n",
        "        result: Optional Vector to assemble the linear form into.\n",
        "        u_func_for_lifting: Current solution as dolfinx.fem.Function. Used for lifting BCs.\n",
        "        alpha: For BC\n",
        "        b: Optional vector to store the temporary vector for Lagrange basis.\n",
        "    Returns:\n",
        "        Linear form vector for PNS.\n",
        "    \"\"\"\n",
        "    comm = pnsObject['comm']\n",
        "    if result is None:\n",
        "        result = PETSc.Vec().createSeq(pnsObject['prolongation_matrix'].getSize()[1], comm=comm)\n",
        "    K = pnsObject['prolongation_matrix']\n",
        "    with exclude_time():\n",
        "        if b is None:\n",
        "            #Argument from L -> extract_function_spaces(L)\n",
        "            b = create_vector(extract_function_spaces(L))\n",
        "        with b.localForm() as bl:\n",
        "            bl.set(0)\n",
        "        dolfinx.fem.petsc.assemble_vector(b, L)\n",
        "        if len(lagrange_bcs) > 0:\n",
        "            dolfinx.fem.petsc.apply_lifting(b, [bilinear_form], [lagrange_bcs], x0=[u_func_for_lifting] if u_func_for_lifting is not None else [], alpha=alpha)\n",
        "            dolfinx.fem.petsc.set_bc(b, lagrange_bcs, x0=u_func_for_lifting, alpha=alpha)\n",
        "            #x0_arg_for_lifting = [u_func_for_lifting.x.petsc_vec] if u_func_for_lifting is not None else []\n",
        "            #dolfinx.fem.petsc.apply_lifting(b, [bilinear_form], [lagrange_bcs], x0=x0_arg_for_lifting, alpha=alpha)\n",
        "            #dolfinx.fem.petsc.set_bc(b, lagrange_bcs, x0=u_func_for_lifting.x.petsc_vec, alpha=alpha)\n",
        "\n",
        "    lifted_b = b # if no pns BC\n",
        "\n",
        "    # TODO: account for x0 and alpha\n",
        "    if bc is not None:\n",
        "        AK = A.matMult(K)\n",
        "        x_g = bc.getXg()\n",
        "        lifted_b = PETSc.Vec().createSeq(K.getSize()[0], comm=comm)\n",
        "        AK.mult(x_g, lifted_b)\n",
        "        lifted_b.aypx(-1, b)\n",
        "    K.multTranspose(lifted_b, result)\n",
        "    if bc is not None:\n",
        "        bc.setVector(result)\n",
        "    result.assemble()\n",
        "    return result, b\n",
        "\n",
        "def pnsAssign(source_pns: PETSc.Vec, target_lagrange: dolfinx.fem.Function, pnsObject):\n",
        "    \"\"\"Assign the value from source vector in Lagrange basis to target vector in PNS basis.\n",
        "    Args:\n",
        "        source_pns: Source vector in PNS basis.\n",
        "        target_lagrange: Target function in Lagrange basis.\n",
        "        pnsObject: PNS object\n",
        "    \"\"\"\n",
        "    K = pnsObject['prolongation_matrix']\n",
        "    K.mult(source_pns, target_lagrange.x.petsc_vec)\n",
        "\n",
        "def pnsLagrangeAssign(source_lagrange: dolfinx.fem.Function, target_pns: PETSc.Vec, pnsObject):\n",
        "    \"\"\"Assign the value from source vector in PNS basis to target vector in Lagrange basis.\n",
        "    Args:\n",
        "        source_lagrange: Source function in PNS basis.\n",
        "        target_pns: Target vector in Lagrange basis.\n",
        "        pnsObject: PNS object\n",
        "    \"\"\"\n",
        "    K = pnsObject['prolongation_matrix']\n",
        "    K.multTranspose(source_lagrange.x.petsc_vec, target_pns)\n",
        "\n",
        "class PnsLinearProblem:\n",
        "    def __init__(\n",
        "        self,\n",
        "        a: ufl.Form,\n",
        "        L: ufl.Form,\n",
        "        pnsObject,\n",
        "        bc: typing.Optional[dolfinx.fem.DirichletBC] = None,\n",
        "        lagrange_bcs = [],\n",
        "        comm = MPI.COMM_WORLD,\n",
        "        petsc_options: typing.Optional[dict] = None,\n",
        "        form_compiler_options: typing.Optional[dict] = None,\n",
        "        jit_options: typing.Optional[dict] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize solver for a linear variational problem.\n",
        "\n",
        "        Args:\n",
        "            a: Bilinear UFL form or a sequence of sequence of bilinear\n",
        "                forms, the left hand side of the variational problem.\n",
        "            L: Linear UFL form or a sequence of linear forms, the right\n",
        "                hand side of the variational problem.\n",
        "            pnsObject: PNS object\n",
        "            bc(PnsDirichletBC): Dirichlet boundary condition with PNS DOF.\n",
        "            lagrange_bcs: Lagrange basis Dirichlet boundary conditions.\n",
        "            petsc_options: Options that are passed to the linear\n",
        "                algebra backend PETSc. For available choices for the\n",
        "                'petsc_options' kwarg, see the `PETSc documentation\n",
        "                <https://petsc4py.readthedocs.io/en/stable/manual/ksp/>`_.\n",
        "            form_compiler_options: Options used in FFCx compilation of\n",
        "                all forms. Run ``ffcx --help`` at the commandline to see\n",
        "                all available options.\n",
        "            jit_options: Options used in CFFI JIT compilation of C\n",
        "                code generated by FFCx. See `python/dolfinx/jit.py` for\n",
        "                all available options.\n",
        "\n",
        "                available options. Takes priority over all other\n",
        "                option values.\n",
        "\n",
        "        Example::\n",
        "\n",
        "            problem = LinearProblem(a, L, bc, petsc_options={\n",
        "                \"ksp_type\": \"preonly\",\n",
        "                \"pc_type\": \"lu\",\n",
        "                \"pc_factor_mat_solver_type\": \"mumps\"\n",
        "            })\n",
        "        \"\"\"\n",
        "        # Maybe u needs to be in pns for.\n",
        "        # Create K. Maybe k can be represended as a form then create_matrix function can be used\n",
        "        self.pnsObject = pnsObject\n",
        "        self._a = dolfinx.fem.form(a)\n",
        "        self._L = dolfinx.fem.form(L)\n",
        "\n",
        "        self.bc = bc\n",
        "        self.lagrange_bcs = lagrange_bcs\n",
        "\n",
        "        comm = pnsObject['comm']\n",
        "\n",
        "        self._solver = PETSc.KSP().create(comm)\n",
        "        prefix = f\"dolfinx_solve_{id(self)}\"\n",
        "        self._solver.setOptionsPrefix(prefix)\n",
        "\n",
        "        opts = PETSc.Options()\n",
        "        opts.prefixPush(prefix)\n",
        "        if petsc_options:\n",
        "            for key, val in petsc_options.items():\n",
        "                opts[key] = val\n",
        "        opts.prefixPop()\n",
        "        self._solver.setFromOptions()\n",
        "\n",
        "    def solve(self) -> PETSc.Vec:\n",
        "        A_reduced, A = assemble_matrix_pns(self.pnsObject, self._a, self.bc, self.lagrange_bcs)\n",
        "        b_reduced, _ = assemble_vector_pns(self.pnsObject, self._L, A, self.bc, self.lagrange_bcs, self._a, u_func_for_lifting=None) # No solution function available here for linear problem\n",
        "        self._solver.setOperators(A_reduced)\n",
        "        x_reduced = b_reduced.duplicate()\n",
        "        self._solver.solve(b_reduced, x_reduced)\n",
        "        return x_reduced\n",
        "\n",
        "    def __del__(self):\n",
        "        return\n",
        "\n",
        "class PnsNewtonSolver(dolfinx.cpp.nls.petsc.NewtonSolver):\n",
        "    def __init__(self, comm: MPI.Intracomm, problem):\n",
        "        \"\"\"A Newton solver for non-linear problems.\"\"\"\n",
        "        super().__init__(comm)\n",
        "        self.problem = problem\n",
        "        # Create matrix and vector to be used for assembly\n",
        "        # of the non-linear problem\n",
        "        pnsObject = problem.pnsObject\n",
        "        numPnsDof = pnsObject['prolongation_matrix'].getSize()[1]\n",
        "        self._A = PETSc.Mat().createAIJ(size=(numPnsDof, numPnsDof), comm=comm)\n",
        "        self.setJ(problem.J, self._A)\n",
        "        self._b = PETSc.Vec().createSeq(numPnsDof, comm=comm)\n",
        "        self.setF(problem.F, self._b)\n",
        "        self._x = PETSc.Vec().createSeq(numPnsDof, comm=comm)\n",
        "        pnsObject['prolongation_matrix'].multTranspose(problem.u.x.petsc_vec, self._x)\n",
        "        self.set_form(problem.form)\n",
        "\n",
        "    def __del__(self):\n",
        "        self._A.destroy()\n",
        "        self._b.destroy()\n",
        "\n",
        "    def solve(self, u: dolfinx.fem.Function):\n",
        "        \"\"\"Solve non-linear problem into function u. Returns the number\n",
        "        of iterations and if the solver converged.\"\"\"\n",
        "        n, converged = super().solve(self._x)\n",
        "        self.problem.pnsObject['prolongation_matrix'].mult(self._x, u.x.petsc_vec)\n",
        "        u.x.scatter_forward()\n",
        "        return n, converged\n",
        "\n",
        "    @property\n",
        "    def A(self) -> PETSc.Mat:  # type: ignore\n",
        "        \"\"\"Jacobian matrix\"\"\"\n",
        "        return self._A\n",
        "\n",
        "    @property\n",
        "    def b(self) -> PETSc.Vec:  # type: ignore\n",
        "        \"\"\"Residual vector\"\"\"\n",
        "        return self._b\n",
        "\n",
        "    def setP(self, P: dolfinx.fem.Function, Pmat: PETSc.Mat):  # type: ignore\n",
        "        \"\"\"\n",
        "        Set the function for computing the preconditioner matrix\n",
        "\n",
        "        Args:\n",
        "            P: Function to compute the preconditioner matrix\n",
        "            Pmat: Matrix to assemble the preconditioner into\n",
        "\n",
        "        \"\"\"\n",
        "        super().setP(P, Pmat)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PnsNonlinearProblem:\n",
        "    \"\"\"Nonlinear problem class for solving the non-linear problems.\n",
        "\n",
        "    Solves problems of the form :math:`F(u, v) = 0 \\ \\forall v \\in V` using\n",
        "    PETSc as the linear algebra backend.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        F: ufl.form.Form,\n",
        "        u: dolfinx.fem.Function,\n",
        "        pnsObject,\n",
        "        bcs: list[dolfinx.fem.DirichletBC] = [],\n",
        "        J: ufl.form.Form = None,\n",
        "        form_compiler_options: typing.Optional[dict] = None,\n",
        "        jit_options: typing.Optional[dict] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize solver for solving a non-linear problem using Newton's method`.\n",
        "\n",
        "        Args:\n",
        "            F: The PDE residual F(u, v)\n",
        "            u: The unknown\n",
        "            bcs: List of Dirichlet boundary conditions\n",
        "            J: UFL representation of the Jacobian (Optional)\n",
        "            form_compiler_options: Options used in FFCx\n",
        "                compilation of this form. Run ``ffcx --help`` at the\n",
        "                command line to see all available options.\n",
        "            jit_options: Options used in CFFI JIT compilation of C\n",
        "                code generated by FFCx. See ``python/dolfinx/jit.py``\n",
        "                for all available options. Takes priority over all\n",
        "                other option values.\n",
        "\n",
        "        Example::\n",
        "\n",
        "            problem = LinearProblem(F, u, [bc0, bc1])\n",
        "        \"\"\"\n",
        "        self.u = u\n",
        "        self._L = _create_form(\n",
        "            F, form_compiler_options=form_compiler_options, jit_options=jit_options\n",
        "        )\n",
        "\n",
        "        # Create the Jacobian matrix, dF/du\n",
        "        if J is None:\n",
        "            V = extract_function_spaces(u) #u.function_space -> extract_function_spaces(u)\n",
        "            du = ufl.TrialFunction(V)\n",
        "            J = ufl.derivative(F, u, du)\n",
        "\n",
        "        self._a = _create_form(\n",
        "            J, form_compiler_options=form_compiler_options, jit_options=jit_options\n",
        "        )\n",
        "        self.bcs = bcs\n",
        "        self.pnsObject = pnsObject\n",
        "        self.bTemp = create_vector(self._L)\n",
        "        self.Atemp = create_matrix(self._a)\n",
        "        self.AKtemp = PETSc.Mat()\n",
        "        self.KTAKtemp = PETSc.Mat()\n",
        "\n",
        "    @property\n",
        "    def L(self) -> ufl.form.Form:\n",
        "        \"\"\"Compiled linear form (the residual form)\"\"\"\n",
        "        return self._L\n",
        "\n",
        "    @property\n",
        "    def a(self) -> ufl.form.Form:\n",
        "        \"\"\"Compiled bilinear form (the Jacobian form)\"\"\"\n",
        "        return self._a\n",
        "\n",
        "    def form(self, x: PETSc.Vec) -> None:\n",
        "        \"\"\"This function is called before the residual or Jacobian is\n",
        "        computed. This is usually used to update ghost values.\n",
        "\n",
        "        Args:\n",
        "           x: The vector containing the latest solution\n",
        "        \"\"\"\n",
        "        # x.ghostUpdate(addv=PETSc.InsertMode.INSERT, mode=PETSc.ScatterMode.FORWARD)\n",
        "        self.pnsObject['prolongation_matrix'].mult(x, self.u.x.petsc_vec)\n",
        "\n",
        "    def F(self, x: PETSc.Vec, b: PETSc.Vec) -> None:\n",
        "        \"\"\"Assemble the residual F into the vector b.\n",
        "\n",
        "        Args:\n",
        "            x: The vector containing the latest solution\n",
        "            b: Vector to assemble the residual into\n",
        "        \"\"\"\n",
        "        # # Reset the residual vector\n",
        "        # with b.localForm() as b_local:\n",
        "        #     b_local.set(0.0)\n",
        "        # assemble_vector(b, self._L)\n",
        "\n",
        "        # # Apply boundary condition\n",
        "        # apply_lifting(b, [self._a], bcs=[self.bcs], x0=[x], alpha=-1.0)\n",
        "        # b.ghostUpdate(addv=PETSc.InsertMode.ADD, mode=PETSc.ScatterMode.REVERSE)\n",
        "        # set_bc(b, self.bcs, x, -1.0)\n",
        "\n",
        "        assemble_vector_pns(self.pnsObject, self._L, lagrange_bcs=self.bcs, bilinear_form=self._a, result=b, u_func_for_lifting=self.u, alpha=-1.0, b=self.bTemp)\n",
        "        # print(b.array)\n",
        "        # print(\"----------------\\n\\n\\n-------------------\")\n",
        "        # print(\"Residual norm:\", b.norm())\n",
        "\n",
        "    def J(self, x: PETSc.Vec, A: PETSc.Mat) -> None:\n",
        "        \"\"\"Assemble the Jacobian matrix.\n",
        "\n",
        "        Args:\n",
        "            x: The vector containing the latest solution\n",
        "        \"\"\"\n",
        "        # A.zeroEntries()\n",
        "        # assemble_matrix(A, self._a, self.bcs)\n",
        "        # A.assemble()\n",
        "        assemble_matrix_pns(self.pnsObject, self._a, lagrange_bcs=self.bcs, result=A, A=self.Atemp, AK=self.AKtemp, KTAK=self.KTAKtemp)\n",
        "\n",
        "class PnsDirichletBC:\n",
        "    def __init__(self, pnsObject, value: np.ndarray, dof: np.ndarray):\n",
        "        self.value = value\n",
        "        self.dof = dof\n",
        "        self.pnsObject = pnsObject\n",
        "\n",
        "    def setVector(self, x: PETSc.Vec):\n",
        "        x.setValues(self.dof, self.value)\n",
        "        x.assemble()\n",
        "\n",
        "    def setMatrix(self, mat: PETSc.Mat):\n",
        "        mat.zeroRowsColumns(self.dof, diag = 1)\n",
        "        mat.assemble()\n",
        "        # mat.zeroRows(self.dof, diag=1)\n",
        "\n",
        "    def getXg(self):\n",
        "        x_g = PETSc.Vec().createSeq(self.pnsObject['prolongation_matrix'].getSize()[1], comm=self.pnsObject['comm'])\n",
        "        x_g.setValues(self.dof, self.value)\n",
        "        x_g.assemble()\n",
        "        return x_g\n",
        "\n",
        "def loadPns(file_name: str, numElements = 1, set_boundary_gradient=False, comm = MPI.COMM_WORLD):\n",
        "    control_mesh = pns.Pns_control_mesh.from_file(file_name)\n",
        "    if set_boundary_gradient:\n",
        "        augmented_control_mesh = pns.set_boundary_gradient(control_mesh)\n",
        "    else:\n",
        "        augmented_control_mesh = control_mesh\n",
        "    pnsLagrangePatchBuilders = pns.get_patch_builders(control_mesh)\n",
        "    pnsPatchBuilders = pns.get_patch_builders(control_mesh)\n",
        "    pnsAugmentedLagrangePatchBuilders = pns.get_patch_builders(augmented_control_mesh)\n",
        "    pnsAugmentedPatchBuilders = pns.get_patch_builders(augmented_control_mesh)\n",
        "    if len(pnsLagrangePatchBuilders) == 0:\n",
        "        raise Exception(\"No patches found\")\n",
        "    flatPatches = []\n",
        "    numPatches = 0\n",
        "    for pb in pnsLagrangePatchBuilders:\n",
        "        pb.toLagrange()\n",
        "    for pb in pnsAugmentedLagrangePatchBuilders:\n",
        "        pb.toLagrange()\n",
        "    for pb in pnsPatchBuilders:\n",
        "        for patch in pb.build_patches(control_mesh):\n",
        "            flatPatches.append(patch)\n",
        "            numPatches += 1\n",
        "        pb.degRaise()\n",
        "    for pb in pnsAugmentedPatchBuilders:\n",
        "        pb.degRaise()\n",
        "    numVerts = len(control_mesh.get_vertices())\n",
        "    pnsObject = {'lagrangePatchBuilders': pnsLagrangePatchBuilders, 'patchBuilders': pnsPatchBuilders, 'augmentedLagrangePatchBuilders': pnsAugmentedLagrangePatchBuilders, 'augmentedPatchBuilders': pnsAugmentedPatchBuilders, 'numPatches': numPatches, 'numVerts': numVerts, 'control_mesh': control_mesh, \"flat_patches\": flatPatches, \"numElements\": numElements, \"comm\": comm}\n",
        "    K = assemble_prolongation_matrix(pnsObject)\n",
        "    pnsObject[\"prolongation_matrix\"] = K\n",
        "    return pnsObject\n",
        "\n",
        "def createPnsDolfinxMesh(pnsObject) -> dolfinx.mesh.Mesh:\n",
        "    x = []\n",
        "    cells = []\n",
        "    idx = 0\n",
        "    temp = 0\n",
        "    for pb in pnsObject['lagrangePatchBuilders']:\n",
        "        lagrangePatches = pb.build_patches(pnsObject['control_mesh'])\n",
        "        for patch in lagrangePatches:\n",
        "            temp += 1\n",
        "            lagrangeCoeffs = patch.bb_coefs\n",
        "            currX = [0]*16\n",
        "            cpIdx = 0\n",
        "            for row in lagrangeCoeffs:\n",
        "                for col in row:\n",
        "                    currX[cubicLagrangeDofOrder[cpIdx]] = [col[0], col[1], col[2]]\n",
        "                    cpIdx += 1\n",
        "            x.extend(currX)\n",
        "            cells.append(list(range(idx, idx+16)))\n",
        "            idx += 16\n",
        "    domain = ufl.Mesh(\n",
        "        basix.ufl.element(\n",
        "            \"Lagrange\",\n",
        "            \"quadrilateral\",\n",
        "            3,\n",
        "            lagrange_variant=basix.LagrangeVariant.equispaced,\n",
        "            shape=(3,),\n",
        "        )\n",
        "    )\n",
        "\n",
        "    mesh = dolfinx.mesh.create_mesh(pnsObject[\"comm\"], cells, domain, x)\n",
        "    return mesh\n",
        "\n",
        "def pnsFunctionSpace(mesh, pnsObject) -> dolfinx.fem.FunctionSpace:\n",
        "    el = basix.ufl.element(\n",
        "            \"Lagrange\",\n",
        "            \"quadrilateral\",\n",
        "            3,\n",
        "            lagrange_variant=basix.LagrangeVariant.equispaced,\n",
        "        )\n",
        "    if pnsObject['numElements'] > 1:\n",
        "        el = basix.ufl.mixed_element([el] * pnsObject['numElements'])\n",
        "    V = dolfinx.fem.functionspace(mesh, el)\n",
        "    return V\n",
        "\n",
        "\n",
        "\n",
        "# testProlongationMatrix(pnsObject)\n",
        "\n",
        "# \"\"\"## Visualize Pns\"\"\"\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "from math import comb\n",
        "from functools import cache\n",
        "\n",
        "class PnsVisualizer:\n",
        "    def __init__(self, pnsObject, dt=0):\n",
        "        self.pnsObject = pnsObject\n",
        "        self.dt = dt\n",
        "        self.funcList = []\n",
        "\n",
        "    def addFunc(self, valDofs):\n",
        "        self.funcList.append(valDofs.copy())\n",
        "\n",
        "    def visualizePns(self, filename, val_range=None):\n",
        "        \"\"\"\n",
        "        Generates a file that can be visualized by https://cise.ufl.edu/~p.gupta/pns-fea-visualizer/\n",
        "        \"\"\"\n",
        "\n",
        "        allPatchCps = np.array([\n",
        "            patch.bb_coefs\n",
        "            for pb in self.pnsObject['patchBuilders']\n",
        "            for patch in pb.build_patches(self.pnsObject['control_mesh'])\n",
        "        ])  # shape (P,4,4,3)\n",
        "\n",
        "        num_patches = allPatchCps.shape[0]\n",
        "        num_timesteps = len(self.funcList)\n",
        "        # build val‐function control‐point arrays\n",
        "        all_valPatchCps = np.array([\n",
        "            patch.bb_coefs\n",
        "            for valDofs in self.funcList\n",
        "            for pb in self.pnsObject['augmentedPatchBuilders']\n",
        "            for patch in pb.build_patches(\n",
        "                pns.Pns_control_mesh.from_data(\n",
        "                    [(v,0,0) for v in valDofs],\n",
        "                    []\n",
        "                )\n",
        "            )\n",
        "        ])  # shape (num_timesteps*P,4,4,3)\n",
        "        all_valPatchCps = all_valPatchCps[:, :, :, 0]  # take x‐coord as scalar value\n",
        "        all_valPatchCps = all_valPatchCps.reshape(num_timesteps, num_patches, 4, 4)  # shape (num_timesteps,P,4,4)\n",
        "        if val_range is None:\n",
        "            min_val = np.min(all_valPatchCps)\n",
        "            max_val = np.max(all_valPatchCps)\n",
        "        else:\n",
        "            min_val, max_val = val_range\n",
        "        out = [str(num_patches), str(num_timesteps), str(min_val), str(max_val)]\n",
        "\n",
        "        for p in range(num_patches):\n",
        "            out.append(\"3 3\")  # u‐degree, v‐degree\n",
        "            out.append(\" \".join(map(str, allPatchCps[p].flatten().tolist())))\n",
        "            out.append(\" \".join(map(str, all_valPatchCps[:, p].flatten().tolist())))\n",
        "\n",
        "        out_str = \"\\n\".join(out)\n",
        "\n",
        "        with open(filename, \"w\") as f:\n",
        "            f.write(out_str)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PnsMatrixNonlinearSolver(PETSc.KSP):\n",
        "    def __init__(self,\n",
        "                 comm: MPI.Intracomm,\n",
        "                 pnsObject,\n",
        "                 lhs: ufl.form.Form, # UFL form for Jacobian (e.g., a1)\n",
        "                 rhs: ufl.form.Form, # UFL form for residual L (e.g., L1)\n",
        "                 F: ufl.form.Form, # UFL form for the full residual (e.g., F1)\n",
        "                 u: dolfinx.fem.Function, # The dolfinx.fem.Function to be solved for (e.g., u_, p_)\n",
        "                 J: ufl.form.Form = None, # UFL form for Jacobian (if explicitly provided)\n",
        "                 bcs: list[dolfinx.fem.DirichletBC] = [],\n",
        "                 form_compiler_options: typing.Optional[dict] = None,\n",
        "                 jit_options: typing.Optional[dict] = None):\n",
        "        \"\"\"A Newton solver for non-linear problems.\"\"\"\n",
        "        \"\"\"Solves Nonlinear Ax = b problems\n",
        "\n",
        "        solver2 = PETSc.KSP().create(mesh.comm)\n",
        "        solver2.setOperators(A2)\n",
        "        solver2.setType(PETSc.KSP.Type.BCGS)\n",
        "        pc2 = solver2.getPC()\n",
        "        pc2.setType(PETSc.PC.Type.HYPRE)\n",
        "        pc2.setHYPREType(\"boomeramg\")\n",
        "        \"\"\"\n",
        "        super().create(comm)\n",
        "        self.pnsObject = pnsObject\n",
        "        self.u = u\n",
        "        self.bcs = bcs\n",
        "        self._F = F\n",
        "        if J is None:\n",
        "            V = self.u.function_space\n",
        "            du = ufl.TrialFunction(V)\n",
        "            self._J = ufl.derivative(self._F, self.u, du) # UFL form for F1\n",
        "        else:\n",
        "            self._J = J\n",
        "\n",
        "\n",
        "        # Create matrix and vector to be used for assembly\n",
        "        # of the non-linear problem\n",
        "        pnsObject = pnsObject\n",
        "        numPnsDof = pnsObject['prolongation_matrix'].getSize()[1]\n",
        "        self._A = PETSc.Mat().createAIJ(size=(numPnsDof, numPnsDof), comm=comm)\n",
        "        self.setJ(self._J, self._A)\n",
        "        self._b = PETSc.Vec().createSeq(numPnsDof, comm=comm)\n",
        "        self.setF(self._F, self._b)\n",
        "        self._x = PETSc.Vec().createSeq(numPnsDof, comm=comm)\n",
        "        pnsObject['prolongation_matrix'].multTranspose(self.u.x.petsc_vec, self._x)\n",
        "        self.set_form(self._F)\n",
        "\n",
        "    def __del__(self):\n",
        "        self._A.destroy()\n",
        "        self._b.destroy()\n",
        "\n",
        "    def solve(self, u: dolfinx.fem.Function):\n",
        "        \"\"\"Solve non-linear problem into function u. Returns the number\n",
        "        of iterations and if the solver converged.\"\"\"\n",
        "        n, converged = super().solve(self._x)\n",
        "        self.problem.pnsObject['prolongation_matrix'].mult(self._x, u.x.petsc_vec)\n",
        "        u.x.scatter_forward()\n",
        "        return n, converged\n",
        "\n",
        "    @property\n",
        "    def A(self) -> PETSc.Mat:  # type: ignore\n",
        "        \"\"\"Jacobian matrix\"\"\"\n",
        "        return self._A\n",
        "\n",
        "    @property\n",
        "    def b(self) -> PETSc.Vec:  # type: ignore\n",
        "        \"\"\"Residual vector\"\"\"\n",
        "        return self._b\n",
        "\n",
        "    def setP(self, P: dolfinx.fem.Function, Pmat: PETSc.Mat):  # type: ignore\n",
        "        \"\"\"\n",
        "        Set the function for computing the preconditioner matrix\n",
        "\n",
        "        Args:\n",
        "            P: Function to compute the preconditioner matrix\n",
        "            Pmat: Matrix to assemble the preconditioner into\n",
        "\n",
        "        \"\"\"\n",
        "        super().setP(P, Pmat)"
      ],
      "metadata": {
        "id": "z1l7mCiy4zwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLrp65bDrvz6"
      },
      "source": [
        "#Navier Stokes PnS w/ Fenicsx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGNLBHiervz7"
      },
      "outputs": [],
      "source": [
        "\n",
        "from mpi4py import MPI\n",
        "from petsc4py import PETSc\n",
        "import numpy as np\n",
        "import pyvista as pv\n",
        "\n",
        "from dolfinx.fem import Constant, Function, functionspace, assemble_scalar, dirichletbc, form, locate_dofs_geometrical, locate_dofs_topological\n",
        "from dolfinx.fem.petsc import assemble_matrix, assemble_vector, apply_lifting, create_vector, set_bc\n",
        "from dolfinx.io import VTXWriter\n",
        "from dolfinx.mesh import create_unit_square\n",
        "from dolfinx.plot import vtk_mesh\n",
        "from basix.ufl import element\n",
        "from ufl import (FacetNormal, Identity, TestFunction, TrialFunction,TrialFunctions, TestFunctions,\n",
        "                 div, dot, ds, dx, inner, lhs, nabla_grad, rhs, sym)\n",
        "from dolfinx.mesh import locate_entities_boundary, locate_entities\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (C) 2023 Jørgen S. Dokken and Halvor Herlyng\n",
        "#\n",
        "# SPDX-License-Identifier:    MIT\n",
        "from normals_and_tangents import *"
      ],
      "metadata": {
        "id": "Rmg1K_XfLQfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHnfUxNkrvz7",
        "outputId": "39f8ecca-7622-4a10-b3d1-c398e4f84905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "airplane.obj  normals_and_tangents.py  Pressure     sample_data\n",
            "Flow\t      polyhedral_splines       __pycache__\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Adapted from\n",
        "Jørgen S. Dokken, Test Problem 1: Channel flow(Poiseuille), https://jsdokken.com/dolfinx-tutorial/chapter2/ns_code1.html\n",
        "\"\"\"\n",
        "!ls\n",
        "pnsObject = loadPns(\"airplane.obj\", numElements=3)\n",
        "pnsObject2 = loadPns(\"airplane.obj\")\n",
        "mesh = createPnsDolfinxMesh(pnsObject)\n",
        "tdim = mesh.topology.dim\n",
        "fdim = mesh.topology.dim-1\n",
        "mesh.topology.create_connectivity(fdim, mesh.topology.dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f-8bl_2rvz7"
      },
      "outputs": [],
      "source": [
        "V = pnsFunctionSpace(mesh, pnsObject)\n",
        "Q = pnsFunctionSpace(mesh, pnsObject2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeg1UnDVrvz7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Constants\n",
        "\"\"\"\n",
        "t = 5 #T_0\n",
        "T = 10 #T_1\n",
        "num_steps = 50\n",
        "dt = dolfinx.fem.Constant(mesh, (T-t) / num_steps)\n",
        "pi = 3.141593653589\n",
        "err = 1e-8 #Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtEPoNtkrvz7"
      },
      "outputs": [],
      "source": [
        "u = TrialFunction(V)\n",
        "v = TestFunction(V)\n",
        "p = TrialFunction(Q)\n",
        "q = TestFunction(Q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGd93KaCrvz7",
        "outputId": "5bfcb834-a7d9-4b8a-d625-cb66ce861513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-9.60034752 -3.96267653 -0.95872593] [1.57978475 3.96047568 2.36406612]\n"
          ]
        }
      ],
      "source": [
        "coords = mesh.geometry.x     # shape (num_vertices, gdim)\n",
        "bmin   = coords.min(axis=0) # array([min_x, min_y, min_z])\n",
        "bmax   = coords.max(axis=0)\n",
        "print(bmin, bmax)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Computes Subspace information\n",
        "\"\"\"\n",
        "V0 = V.sub(0)\n",
        "V1 = V.sub(1)\n",
        "V2 = V.sub(2)\n",
        "V0_c, map0 = V0.collapse()\n",
        "V1_c, map1 = V1.collapse()\n",
        "V2_c, map2 = V2.collapse()"
      ],
      "metadata": {
        "id": "TxPRui88Ze1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Find Facet Normal vectors, Doesnt Find all due to Less Vertices on Pns Mesh :(\n",
        "\"\"\"\n",
        "facets_normal = locate_entities(mesh, fdim, lambda x: np.isclose(x[0], x[0]))\n",
        "ones = np.ones(len(facets_normal), dtype=np.int32)\n",
        "facet_tags = dolfinx.mesh.meshtags(mesh, tdim, facets_normal, ones)\n",
        "tangent, interior = False, False\n",
        "n0, n1, n2 = facet_vector_approximation(V, facet_tags, 1, tangent, interior)\n",
        "\"\"\"\n",
        "Constructs Parent Function\n",
        "\"\"\"\n",
        "nP = dolfinx.fem.Function(V)\n",
        "nP.x.array[V.sub(0).dofmap.list.flatten()] = n0.x.array\n",
        "nP.x.array[V.sub(1).dofmap.list.flatten()] = n1.x.array\n",
        "nP.x.array[V.sub(2).dofmap.list.flatten()] = n2.x.array"
      ],
      "metadata": {
        "id": "SEOWOJ-9B2Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Finds Coordinates of Collapes Subspaces, Mapes them back to Coordinate on original Mesh\n",
        "\"\"\"\n",
        "coords0, coords1, coords2 = V0_c.tabulate_dof_coordinates(), V1_c.tabulate_dof_coordinates(), V2_c.tabulate_dof_coordinates()\n",
        "x, y, z = nP.x.array[map0], nP.x.array[map1], nP.x.array[map2]\n",
        "values = [[], [], []]\n",
        "vector_values = [[], [], []]\n",
        "for i in range(len(coords0)):\n",
        "  if np.isclose(x[i], -1.0, rtol = 0.05) and np.isclose(coords0[i][0], bmin[0], rtol=0.05):\n",
        "    values[0].append(coords0[i][0])\n",
        "    values[1].append(coords1[i][1])\n",
        "    values[2].append(coords2[i][2])\n",
        "    vector_values[0].append(x[i])\n",
        "    vector_values[1].append(y[i])\n",
        "    vector_values[2].append(z[i])\n",
        "while len(values[0]) < 4188:\n",
        "  values[0].append(-11)\n",
        "  values[1].append(-11)\n",
        "  values[2].append(-11)\n",
        "\n"
      ],
      "metadata": {
        "id": "6cACm2cxMBRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def closen0(x):\n",
        "  return np.isclose(x[0], values[0], rtol=0.16)\n",
        "def closen1(x):\n",
        "  return np.isclose(x[1], values[1], rtol=0.2)\n",
        "def closen2(x):\n",
        "  return np.isclose(x[2], values[2], rtol=0.2)"
      ],
      "metadata": {
        "id": "r-HMFluokq4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Flow Boundary Conditions\n",
        "\"\"\"\n",
        "facets_1 = locate_entities(mesh, fdim, closen0)\n",
        "dofs1 = locate_dofs_topological(V0, fdim, facets_1)\n",
        "u0 = dolfinx.fem.Function(V0_c)\n",
        "u0.interpolate(lambda x: np.sin(x[0]) + np.cos(x[0]) + 10)\n",
        "bc1 = dirichletbc(u0, dofs1)\n",
        "\n",
        "facets_2 = locate_entities(mesh, fdim, closen1)\n",
        "dofs2 = locate_dofs_topological(V1, fdim, facets_2)\n",
        "u1 = dolfinx.fem.Function(V1_c)\n",
        "u1.interpolate(lambda x: x[0] * np.cos(x[0]))\n",
        "bc2 = dirichletbc(u1, dofs2)\n",
        "\n",
        "facets_3 = locate_entities(mesh, fdim, closen2)\n",
        "dofs3 = locate_dofs_topological(V2, fdim, facets_3)\n",
        "u2 = dolfinx.fem.Function(V2_c)\n",
        "u2.interpolate(lambda x: x[0] * np.sin(x[0]))\n",
        "bc3 = dirichletbc(u2, dofs3)\n",
        "print(len(facets_1), len(facets_2), len(facets_3))\n",
        "bcu = [bc1, bc2, bc3]"
      ],
      "metadata": {
        "id": "NSRZgHQTSh2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144ab544-1f65-4d07-f9dd-abe9d3dcf08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56 0 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Pressure Boundary Conditions\n",
        "\"\"\"\n",
        "scalar_random = np.random.uniform(0, 1, size = u0.x.array.size)\n",
        "def pressure(x):\n",
        "  return np.isclose(x[0], x[0])\n",
        "facets_4 = locate_entities(mesh, fdim, pressure)\n",
        "dofs4 = locate_dofs_topological(Q, fdim, facets_4)\n",
        "v0 = dolfinx.fem.Function(Q)\n",
        "v0.interpolate(lambda x: (x[0] * 0) + 1)\n",
        "v0.x.array[:] *= scalar_random\n",
        "bc4 = dirichletbc(v0, dofs4)\n",
        "print(len(facets_4))\n",
        "bcp = [bc4]"
      ],
      "metadata": {
        "id": "zaF8JytgSguc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9647ed5-e22f-44ef-b189-4455d056b520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SowYSfPlrvz8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "From Channel Flow\n",
        "\"\"\"\n",
        "u_n = Function(V)\n",
        "u_n.name = \"u_n\"\n",
        "U = 0.5 * (u_n + u)\n",
        "n = FacetNormal(mesh)\n",
        "f = Constant(mesh, PETSc.ScalarType((1, 1, 1))) #Forcing Function\n",
        "k = Constant(mesh, PETSc.ScalarType(dt))\n",
        "mu = Constant(mesh, PETSc.ScalarType(1)) #Linear Elasticity\n",
        "rho = Constant(mesh, PETSc.ScalarType(1)) #Density"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVHzWPymrvz8"
      },
      "outputs": [],
      "source": [
        "def epsilon(u):\n",
        "    return sym(nabla_grad(u))\n",
        "\n",
        "# Define stress tensor\n",
        "def sigma(u, p):\n",
        "    return 2 * mu * epsilon(u) - p * Identity(len(u))\n",
        "\n",
        "\n",
        "# Define the variational problem for the first step\n",
        "p_n = Function(Q)\n",
        "p_n.name = \"p_n\"\n",
        "F1 = (rho * dot((u - u_n)/k, v) * dx\n",
        "      + rho * dot(dot(u_n, nabla_grad(u_n)), v) * dx\n",
        "      + inner(sigma(U, p_n), epsilon(v)) * dx\n",
        "      + dot(p_n * n, v) * ds\n",
        "      - dot(mu * nabla_grad(U) * n, v) * ds\n",
        "      - dot(f, v) * dx\n",
        "      )\n",
        "a1 = form(lhs(F1))\n",
        "L1 = form(rhs(F1))\n",
        "\n",
        "# Define variational problem for step 2\n",
        "u_ = Function(V)\n",
        "a2 = form(dot(nabla_grad(p), nabla_grad(q)) * dx)\n",
        "L2 = form(dot(nabla_grad(p_n), nabla_grad(q)) * dx - (rho / k) * div(u_) * q * dx)\n",
        "\n",
        "# Define variational problem for step 3\n",
        "p_ = Function(Q)\n",
        "a3 = form(rho * dot(u, v) * dx)\n",
        "L3 = form(rho * dot(u_, v) * dx - k * dot(nabla_grad(p_ - p_n), v) * dx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "PETSc Options for Solvers\n",
        "\"\"\"\n",
        "petsc_options_1 = {\"setType\":PETSc.KSP.Type.BCGS, \"pc_type\":PETSc.PC.Type.HYPRE, \"pc_hypre_type\":\"boomeramg\"}\n",
        "petsc_options_2 = {\"setType\":PETSc.KSP.Type.BCGS, \"pc_type\":PETSc.PC.Type.HYPRE, \"pc_hypre_type\":\"boomeramg\"}\n",
        "petsc_options_3 = {\"setType\":PETSc.KSP.Type.CG, \"pc_type\":PETSc.PC.Type.SOR}"
      ],
      "metadata": {
        "id": "U-McxQYDcUgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Create solvers\n",
        "\"\"\"\n",
        "problem1 = PnsLinearProblem(a1, L1, pnsObject, lagrange_bcs=bcu, petsc_options=petsc_options_1)\n",
        "problem2 = PnsLinearProblem(a2, L2, pnsObject2, lagrange_bcs=bcp, petsc_options=petsc_options_2)\n",
        "problem3 = PnsLinearProblem(a3, L3, pnsObject, lagrange_bcs=bcu, petsc_options=petsc_options_3)"
      ],
      "metadata": {
        "id": "XmeBAZKJy8NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Creates Pns Visualization\n",
        "\"\"\"\n",
        "flow_vis = PnsVisualizer(pnsObject)\n",
        "pressure_vis = PnsVisualizer(pnsObject2)"
      ],
      "metadata": {
        "id": "CPXEPoJnxBAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsZ3_tD6rvz8",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "for i in range(num_steps+1):\n",
        "    # Step 1: Tentative veolcity step\n",
        "    u_reduced_1 = problem1.solve()\n",
        "    u_.x.scatter_forward()\n",
        "    # Step 2: Pressure corrrection step\n",
        "    p_reduced = problem2.solve()\n",
        "    p_.x.scatter_forward()\n",
        "    # Step 3: Velocity correction step\n",
        "    u_reduced = problem3.solve()\n",
        "    u_.x.scatter_forward()\n",
        "\n",
        "    arr = np.array([u_reduced[i] for i in range(0, u_reduced.getSize(), 3)],\n",
        "               dtype=PETSc.ScalarType)\n",
        "\n",
        "    u_x_reduced = PETSc.Vec().createWithArray(arr, comm=PETSc.COMM_SELF)\n",
        "\n",
        "    #Pressure Visualization\n",
        "    flow_vis.addFunc(u_x_reduced.array.real)\n",
        "    pressure_vis.addFunc(p_reduced.array.real)\n",
        "\n",
        "    # Update variable with solution form this time step\n",
        "    pnsLagrangeAssign(u_n, u_reduced, pnsObject)\n",
        "    pnsLagrangeAssign(p_n, p_reduced, pnsObject2)\n",
        "\n",
        "    p_err = np.linalg.norm(p_reduced.array.real)\n",
        "    u_err = np.linalg.norm(u_reduced.array.real)\n",
        "    u1_err = np.linalg.norm(u_reduced_1.array.real)\n",
        "\n",
        "    #Interpolate the time dependent Boundary Conditions\n",
        "    p_random = np.abs(np.random.randn(u0.x.array.size))\n",
        "    u0.interpolate(lambda x: np.sin(x[0]) + np.cos(x[0]) + 10 * t)\n",
        "    v0.interpolate(lambda x: (0 * x[0]) + 1)\n",
        "    v0.x.array[:]*=p_random\n",
        "\n",
        "    print(f\"Flow @ {float(t):.3f}\")\n",
        "    # Update current time step\n",
        "    t += float(dt.value)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make Gif\n",
        "flow_vis.visualizePns('Flow')\n",
        "pressure_vis.visualizePns('Pressure')"
      ],
      "metadata": {
        "id": "AnCfsfSnqLIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr7Z5ZGi67Z1"
      },
      "source": [
        "#Navier Stokes Fenicsx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsZfYGLj6_uR"
      },
      "outputs": [],
      "source": [
        "\n",
        "from mpi4py import MPI\n",
        "from petsc4py import PETSc\n",
        "import numpy as np\n",
        "import pyvista\n",
        "\n",
        "from dolfinx.fem import Constant, Function, functionspace, assemble_scalar, dirichletbc, form, locate_dofs_geometrical\n",
        "from dolfinx.fem.petsc import assemble_matrix, assemble_vector, apply_lifting, create_vector, set_bc\n",
        "from dolfinx.io import VTXWriter\n",
        "from dolfinx.mesh import create_unit_square\n",
        "from dolfinx.plot import vtk_mesh\n",
        "from basix.ufl import element\n",
        "from ufl import (FacetNormal, Identity, TestFunction, TrialFunction,\n",
        "                 div, dot, ds, dx, inner, lhs, nabla_grad, rhs, sym)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi3tH3SeBaML"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Adapted from\n",
        "Jørgen S. Dokken, Test Problem 1: Channel flow(Poiseuille), https://jsdokken.com/dolfinx-tutorial/chapter2/ns_code1.html\n",
        "\"\"\"\n",
        "!ls\n",
        "comm = MPI.COMM_WORLD\n",
        "nx = 10\n",
        "ny = 10\n",
        "nz = 10\n",
        "mesh = create_box(comm, [[0, 0, 0], [1, 1, 1]], [nx, ny, nz], DFXCellType.hexahedron)\n",
        "finite_element_1 = basix.ufl.element(\n",
        "    \"Lagrange\",\n",
        "    \"hexahedron\",\n",
        "    1,\n",
        "    lagrange_variant=basix.LagrangeVariant.equispaced,\n",
        ")\n",
        "finite_element_3 = basix.ufl.element(\n",
        "    \"Lagrange\",\n",
        "    \"hexahedron\",\n",
        "    1,\n",
        "    shape = (mesh.geometry.dim,),\n",
        "    lagrange_variant=basix.LagrangeVariant.equispaced,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vup3yUw7iwl"
      },
      "outputs": [],
      "source": [
        "V = functionspace(mesh, finite_element_3)\n",
        "Q = functionspace(mesh, finite_element_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmm-fLYs8mh8"
      },
      "outputs": [],
      "source": [
        "t = 0 #T_0\n",
        "T = 1 #T_1\n",
        "num_steps = 100\n",
        "dt = dolfinx.fem.Constant(mesh, T / num_steps)\n",
        "pi = 3.141593653589\n",
        "err = 1e-8 #Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFHQWXal8m9l"
      },
      "outputs": [],
      "source": [
        "u = TrialFunction(V)\n",
        "v = TestFunction(V)\n",
        "p = TrialFunction(Q)\n",
        "q = TestFunction(Q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah5boYNJ1kih"
      },
      "outputs": [],
      "source": [
        "coords = mesh.geometry.x     # shape (num_vertices, gdim)\n",
        "bmin   = coords.min(axis=0) # array([min_x, min_y, min_z])\n",
        "bmax   = coords.max(axis=0)\n",
        "print(bmin, bmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IbVc7Ev_vpb"
      },
      "outputs": [],
      "source": [
        "def walls(x):\n",
        "  #y = 0 or y = 1\n",
        "  #z = 0, z = 1\n",
        "  #Says at any X[0] = 0 it is not triggered to make sure no contradictory boundry conditions\n",
        "  return np.logical_and(\n",
        "      np.logical_or(\n",
        "        np.logical_or(np.isclose(x[1], 0, atol=err), np.isclose(x[1], 1, atol=err)),\n",
        "        np.logical_or(np.isclose(x[2], 0, atol=err), np.isclose(x[2], 1, atol=err))\n",
        "        ),\n",
        "      np.logical_and(\n",
        "          ~np.isclose(x[0], 0, atol=err),\n",
        "          ~np.isclose(x[0], 1, atol=err)\n",
        "        )\n",
        "      )\n",
        "def inflow(x):\n",
        "  #x = 0\n",
        "  return np.isclose(x[0], 0, atol=err)\n",
        "def outflow(x):\n",
        "  #x = 1\n",
        "  return np.isclose(x[0], 1, atol=err)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYPEpdoVAFTI"
      },
      "outputs": [],
      "source": [
        "wall_dofs = locate_dofs_geometrical(V, walls)\n",
        "wall_val = Constant(mesh, PETSc.ScalarType((0, 0, 0))) #np.array((0,) * mesh.geometry.dim, dtype=PETSc.ScalarType)\n",
        "bc_wall = dirichletbc(wall_val, wall_dofs, V)\n",
        "\n",
        "inflow_dofs = locate_dofs_geometrical(V, inflow)\n",
        "inflow_val = Constant(mesh, PETSc.ScalarType((1, 0, 0))) #np.array((1, 0, 0), dtype=PETSc.ScalarType)\n",
        "bc_inflow = dirichletbc(inflow_val, inflow_dofs, V)\n",
        "\n",
        "outflow_dofs = locate_dofs_geometrical(V, outflow)\n",
        "outflow_val = Constant(mesh, PETSc.ScalarType((1, 0, 0))) #np.array((1, 0, 0), dtype = PETSc.ScalarType)\n",
        "bc_outflow = dirichletbc(outflow_val, outflow_dofs, V)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko65QlEg6LeP"
      },
      "outputs": [],
      "source": [
        "bcu = [bc_wall, bc_inflow, bc_outflow]\n",
        "bcp = []\n",
        "bcu=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndnLSNlAAMcX"
      },
      "outputs": [],
      "source": [
        "u_n = Function(V)\n",
        "u_n.name = \"u_n\"\n",
        "U = 0.5 * (u_n + u)\n",
        "n = FacetNormal(mesh)\n",
        "f = Constant(mesh, PETSc.ScalarType((0, 0, 0)))\n",
        "k = Constant(mesh, PETSc.ScalarType(dt))\n",
        "mu = Constant(mesh, PETSc.ScalarType(1))\n",
        "rho = Constant(mesh, PETSc.ScalarType(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dyj1xJpAQ_Z"
      },
      "outputs": [],
      "source": [
        "# Define strain-rate tensor\n",
        "def epsilon(u):\n",
        "    return sym(nabla_grad(u))\n",
        "\n",
        "# Define stress tensor\n",
        "def sigma(u, p):\n",
        "    return 2 * mu * epsilon(u) - p * Identity(len(u))\n",
        "\n",
        "\n",
        "# Define the variational problem for the first step\n",
        "p_n = Function(Q)\n",
        "p_n.name = \"p_n\"\n",
        "F1 = rho * dot((u - u_n) / k, v) * dx\n",
        "F1 += rho * dot(dot(u_n, nabla_grad(u_n)), v) * dx\n",
        "F1 += inner(sigma(U, p_n), epsilon(v)) * dx\n",
        "F1 += dot(p_n * n, v) * ds - dot(mu * nabla_grad(U) * n, v) * ds\n",
        "F1 -= dot(f, v) * dx\n",
        "a1 = form(lhs(F1))\n",
        "L1 = form(rhs(F1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKv0K-dwAWak"
      },
      "outputs": [],
      "source": [
        "A1 = assemble_matrix(a1, bcs=bcu)\n",
        "A1.assemble()\n",
        "b1 = assemble_vector(L1) #-> assemble_vector_pns\n",
        "print(A1.size)\n",
        "print(b1.array.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b64TP_VmAtsm"
      },
      "outputs": [],
      "source": [
        "# Define variational problem for step 2\n",
        "u_ = Function(V)\n",
        "a2 = form(dot(nabla_grad(p), nabla_grad(q)) * dx)\n",
        "L2 = form(dot(nabla_grad(p_n), nabla_grad(q)) * dx - (rho / k) * div(u_) * q * dx)\n",
        "A2 = assemble_matrix(a2, bcs=bcp)\n",
        "A2.assemble()\n",
        "b2 = create_vector(Q, L2)\n",
        "\n",
        "# Define variational problem for step 3\n",
        "p_ = Function(Q)\n",
        "a3 = form(rho * dot(u, v) * dx)\n",
        "L3 = form(rho * dot(u_, v) * dx - k * dot(nabla_grad(p_ - p_n), v) * dx)\n",
        "A3 = assemble_matrix(a3, bcs=bcu)\n",
        "A3.assemble()\n",
        "b3 = create_vector(V, L3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3svUcv3A1Xm"
      },
      "outputs": [],
      "source": [
        "# Solver for step 1\n",
        "solver1 = PETSc.KSP().create(mesh.comm)\n",
        "solver1.setOperators(A1)\n",
        "solver1.setType(PETSc.KSP.Type.BCGS)\n",
        "pc1 = solver1.getPC()\n",
        "pc1.setType(PETSc.PC.Type.HYPRE)\n",
        "pc1.setHYPREType(\"boomeramg\")\n",
        "\n",
        "# Solver for step 2\n",
        "solver2 = PETSc.KSP().create(mesh.comm)\n",
        "solver2.setOperators(A2)\n",
        "solver2.setType(PETSc.KSP.Type.BCGS)\n",
        "pc2 = solver2.getPC()\n",
        "pc2.setType(PETSc.PC.Type.HYPRE)\n",
        "pc2.setHYPREType(\"boomeramg\")\n",
        "\n",
        "# Solver for step 3\n",
        "solver3 = PETSc.KSP().create(mesh.comm)\n",
        "solver3.setOperators(A3)\n",
        "solver3.setType(PETSc.KSP.Type.CG)\n",
        "pc3 = solver3.getPC()\n",
        "pc3.setType(PETSc.PC.Type.SOR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwUHZO_mA6AX"
      },
      "outputs": [],
      "source": [
        "pv.start_xvfb()\n",
        "visualize = pv.Plotter(off_screen=True)\n",
        "visualize.open_gif(\"navier_stokes_cube.gif\", fps=10)\n",
        "\n",
        "topology, cell_types, geometry = vtk_mesh(mesh)\n",
        "\n",
        "# Create PyVista UnstructuredGrid\n",
        "pv_mesh = pv.UnstructuredGrid(topology, cell_types, geometry)\n",
        "\n",
        "actor = visualize.add_mesh(pv_mesh)\n",
        "actor.visibility = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sinusoidal(x):\n",
        "  num_points = x.shape[1] # Get the number of points from the shape of x\n",
        "  return np.vstack((np.sin(x[0] + np.pi),\n",
        "                    np.cos(x[1] + np.pi),\n",
        "                    np.full(num_points, 0.))) # Create an array of zeros with the correct number of elements\n",
        "u0 = Function(V)\n",
        "u0.interpolate(lambda x: sinusoidal(x))\n",
        "u0.x.scatter_forward()"
      ],
      "metadata": {
        "id": "jzRebPUE0vLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOmHu6TbMwoh"
      },
      "outputs": [],
      "source": [
        "t=0\n",
        "for i in range(num_steps):\n",
        "    # Update current time step\n",
        "    print(f\"Flow @ {float(t):.3f}\")\n",
        "    visualize.add_title(f\"Flow @ {float(t):.3f}\", font_size=16)\n",
        "    t += dt\n",
        "\n",
        "    # Step 1: Tentative veolcity step\n",
        "    with b1.localForm() as loc_1:\n",
        "        loc_1.set(0)\n",
        "    assemble_vector(b1, L1) # -> assemble_vector_pns\n",
        "    apply_lifting(b1, [a1], [bcu]) #in assemble vector pns\n",
        "    b1.ghostUpdate(addv=PETSc.InsertMode.ADD_VALUES, mode=PETSc.ScatterMode.REVERSE) #in pns Jacobian? seems to be for parallel processing?\n",
        "    set_bc(b1, bcu) #in assemble vector pns\n",
        "    solver1.solve(b1, u_.x.petsc_vec)\n",
        "    print(b1.getSize(), u_.x.petsc_vec.getSize())\n",
        "    u_.x.scatter_forward()\n",
        "\n",
        "\n",
        "    # Step 2: Pressure corrrection step\n",
        "    with b2.localForm() as loc_2:\n",
        "        loc_2.set(0)\n",
        "    assemble_vector(b2, L2)\n",
        "    apply_lifting(b2, [a2], [bcp])\n",
        "    b2.ghostUpdate(addv=PETSc.InsertMode.ADD_VALUES, mode=PETSc.ScatterMode.REVERSE)\n",
        "    set_bc(b2, bcp)\n",
        "    solver2.solve(b2, p_.x.petsc_vec)\n",
        "    p_.x.scatter_forward()\n",
        "\n",
        "    # Step 3: Velocity correction step\n",
        "    with b3.localForm() as loc_3:\n",
        "        loc_3.set(0)\n",
        "    assemble_vector(b3, L3)\n",
        "    b3.ghostUpdate(addv=PETSc.InsertMode.ADD_VALUES, mode=PETSc.ScatterMode.REVERSE)\n",
        "    set_bc(b3, bcu)\n",
        "    solver3.solve(b3, u_.x.petsc_vec)\n",
        "    u_.x.scatter_forward()\n",
        "    # Update variable with solution form this time step\n",
        "    u_n.x.array[:] = u_.x.array[:]\n",
        "    p_n.x.array[:] = p_.x.array[:]\n",
        "\n",
        "\n",
        "    #Reshapes into vectors\n",
        "    if i == 0:\n",
        "      print(u_n.x.array.shape)\n",
        "    vectors = u_n.x.array.reshape((-1, 3))\n",
        "    pv_mesh[\"vectors\"] = vectors\n",
        "\n",
        "    glyphs = pv_mesh.glyph(orient=\"vectors\", scale=False, factor=0.05)\n",
        "    actor = visualize.add_mesh(glyphs)\n",
        "    visualize.write_frame()\n",
        "    visualize.clear()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ctv-ZCUOM48S"
      },
      "outputs": [],
      "source": [
        "b1.destroy()\n",
        "b2.destroy()\n",
        "b3.destroy()\n",
        "solver1.destroy()\n",
        "solver2.destroy()\n",
        "solver3.destroy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JfwuH9QND2o"
      },
      "outputs": [],
      "source": [
        "visualize.show(interactive=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnHtnrY7Qk7x"
      },
      "outputs": [],
      "source": [
        "visualize.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFtViHvXSOKg"
      },
      "outputs": [],
      "source": [
        "gif = imageio.mimread(\"navier_stokes_cube.gif\")  # read all frames\n",
        "imageio.mimsave(\"slow_gif.gif\", gif, duration=0.001) #doesnt work"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ciqQQdolViPh",
        "YJzqNJJah3Nj",
        "Yr7Z5ZGi67Z1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}